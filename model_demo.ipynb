{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Demo: MassFormer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/yunyicheng/opt/anaconda3/envs/MF/lib/python3.11/site-packages (4.35.2)\n",
      "Requirement already satisfied: filelock in /Users/yunyicheng/opt/anaconda3/envs/MF/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Users/yunyicheng/opt/anaconda3/envs/MF/lib/python3.11/site-packages (from transformers) (0.19.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/yunyicheng/opt/anaconda3/envs/MF/lib/python3.11/site-packages (from transformers) (1.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/yunyicheng/opt/anaconda3/envs/MF/lib/python3.11/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/yunyicheng/opt/anaconda3/envs/MF/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/yunyicheng/opt/anaconda3/envs/MF/lib/python3.11/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /Users/yunyicheng/opt/anaconda3/envs/MF/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/yunyicheng/opt/anaconda3/envs/MF/lib/python3.11/site-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/yunyicheng/opt/anaconda3/envs/MF/lib/python3.11/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/yunyicheng/opt/anaconda3/envs/MF/lib/python3.11/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/yunyicheng/opt/anaconda3/envs/MF/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/yunyicheng/opt/anaconda3/envs/MF/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/yunyicheng/opt/anaconda3/envs/MF/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/yunyicheng/opt/anaconda3/envs/MF/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/yunyicheng/opt/anaconda3/envs/MF/lib/python3.11/site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/yunyicheng/opt/anaconda3/envs/MF/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: dgl in /Users/yunyicheng/opt/anaconda3/envs/MF/lib/python3.11/site-packages (1.1.2.post1)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /Users/yunyicheng/opt/anaconda3/envs/MF/lib/python3.11/site-packages (from dgl) (1.26.1)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /Users/yunyicheng/opt/anaconda3/envs/MF/lib/python3.11/site-packages (from dgl) (1.11.3)\n",
      "Requirement already satisfied: networkx>=2.1 in /Users/yunyicheng/opt/anaconda3/envs/MF/lib/python3.11/site-packages (from dgl) (3.2.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/yunyicheng/opt/anaconda3/envs/MF/lib/python3.11/site-packages (from dgl) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /Users/yunyicheng/opt/anaconda3/envs/MF/lib/python3.11/site-packages (from dgl) (4.66.1)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /Users/yunyicheng/opt/anaconda3/envs/MF/lib/python3.11/site-packages (from dgl) (5.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/yunyicheng/opt/anaconda3/envs/MF/lib/python3.11/site-packages (from requests>=2.19.0->dgl) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/yunyicheng/opt/anaconda3/envs/MF/lib/python3.11/site-packages (from requests>=2.19.0->dgl) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/yunyicheng/opt/anaconda3/envs/MF/lib/python3.11/site-packages (from requests>=2.19.0->dgl) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/yunyicheng/opt/anaconda3/envs/MF/lib/python3.11/site-packages (from requests>=2.19.0->dgl) (2023.7.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: dgllife in /Users/yunyicheng/opt/anaconda3/envs/MF/lib/python3.11/site-packages (0.3.2)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2 in /Users/yunyicheng/opt/anaconda3/envs/MF/lib/python3.11/site-packages (from dgllife) (1.3.2)\n",
      "Requirement already satisfied: pandas in /Users/yunyicheng/opt/anaconda3/envs/MF/lib/python3.11/site-packages (from dgllife) (2.1.2)\n",
      "Requirement already satisfied: requests>=2.22.0 in /Users/yunyicheng/opt/anaconda3/envs/MF/lib/python3.11/site-packages (from dgllife) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /Users/yunyicheng/opt/anaconda3/envs/MF/lib/python3.11/site-packages (from dgllife) (4.66.1)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /Users/yunyicheng/opt/anaconda3/envs/MF/lib/python3.11/site-packages (from dgllife) (1.26.1)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /Users/yunyicheng/opt/anaconda3/envs/MF/lib/python3.11/site-packages (from dgllife) (1.11.3)\n",
      "Requirement already satisfied: networkx>=2.1 in /Users/yunyicheng/opt/anaconda3/envs/MF/lib/python3.11/site-packages (from dgllife) (3.2.1)\n",
      "Requirement already satisfied: hyperopt in /Users/yunyicheng/opt/anaconda3/envs/MF/lib/python3.11/site-packages (from dgllife) (0.2.7)\n",
      "Requirement already satisfied: joblib in /Users/yunyicheng/opt/anaconda3/envs/MF/lib/python3.11/site-packages (from dgllife) (1.3.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/yunyicheng/opt/anaconda3/envs/MF/lib/python3.11/site-packages (from requests>=2.22.0->dgllife) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/yunyicheng/opt/anaconda3/envs/MF/lib/python3.11/site-packages (from requests>=2.22.0->dgllife) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/yunyicheng/opt/anaconda3/envs/MF/lib/python3.11/site-packages (from requests>=2.22.0->dgllife) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/yunyicheng/opt/anaconda3/envs/MF/lib/python3.11/site-packages (from requests>=2.22.0->dgllife) (2023.7.22)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/yunyicheng/opt/anaconda3/envs/MF/lib/python3.11/site-packages (from scikit-learn>=0.22.2->dgllife) (3.2.0)\n",
      "Requirement already satisfied: six in /Users/yunyicheng/opt/anaconda3/envs/MF/lib/python3.11/site-packages (from hyperopt->dgllife) (1.16.0)\n",
      "Requirement already satisfied: future in /Users/yunyicheng/opt/anaconda3/envs/MF/lib/python3.11/site-packages (from hyperopt->dgllife) (0.18.3)\n",
      "Requirement already satisfied: cloudpickle in /Users/yunyicheng/opt/anaconda3/envs/MF/lib/python3.11/site-packages (from hyperopt->dgllife) (3.0.0)\n",
      "Requirement already satisfied: py4j in /Users/yunyicheng/opt/anaconda3/envs/MF/lib/python3.11/site-packages (from hyperopt->dgllife) (0.10.9.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/yunyicheng/opt/anaconda3/envs/MF/lib/python3.11/site-packages (from pandas->dgllife) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/yunyicheng/opt/anaconda3/envs/MF/lib/python3.11/site-packages (from pandas->dgllife) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/yunyicheng/opt/anaconda3/envs/MF/lib/python3.11/site-packages (from pandas->dgllife) (2023.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers\n",
    "%pip install dgl\n",
    "%pip install dgllife"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dgl\n",
    "import dgllife.utils as chemutils\n",
    "import torch as th\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.utils.data as th_data\n",
    "import massformer.algos1\n",
    "import massformer.algos2\n",
    "from rdkit import Chem\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.data import Data\n",
    "from transformers.models.graphormer.collating_graphormer import GraphormerDataCollator, preprocess_item\n",
    "import src.massformer.utils as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spec_df = pd.read_pickle(\"data/proc_demo/spec_df.pkl\")\n",
    "# mol_df = pd.read_pickle(\"data/proc_demo/mol_df.pkl\")\n",
    "# toy_spec_df = spec_df.sample(n=1000, replace=False, random_state=420)\n",
    "# toy_mol_df = mol_df[mol_df[\"mol_id\"].isin(toy_spec_df[\"mol_id\"])]\n",
    "# toy_spec_df.to_pickle(\"data/proc_demo/toy_spec_df.pkl\")\n",
    "# toy_mol_df.to_pickle(\"data/proc_demo/toy_mol_df.pkl\")\n",
    "# toy_mol_df = toy_mol_df.set_index(\n",
    "#             \"mol_id\", drop=False).sort_index().rename_axis(None)\n",
    "# print(toy_spec_df)\n",
    "# print(toy_mol_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(toy_spec_df)\n",
    "# print(toy_mol_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "class MassFormerDataCollator(GraphormerDataCollator):\n",
    "\n",
    "    def __init__(self, spatial_pos_max=1024):\n",
    "\n",
    "        super().__init__(spatial_pos_max=spatial_pos_max, on_the_fly_processing=False)\n",
    "        # custom init stuff for MassFormer\n",
    "\n",
    "    def __call__(self, items: List[dict]):\n",
    "\n",
    "        print(f\"all keys = {list(items[0].keys())}\")\n",
    "\n",
    "        # this list of arguments is basically what preprocess_item produces\n",
    "        gf_keys = ['input_nodes', 'attn_bias', 'attn_edge_type', 'spatial_pos', 'in_degree', 'out_degree', 'input_edges', 'labels']\n",
    "        gf_related_keys = ['spatial_pos', 'labels', 'y', 'edge_index', 'edge_attr', 'num_nodes', 'attn_bias', 'input_nodes', 'attn_edge_type', 'in_degree', 'input_edges', 'out_degree', 'x']\n",
    "        gf_items = []\n",
    "        for item in items:\n",
    "            gf_item = {}\n",
    "            for k in gf_keys:\n",
    "                # note: some keys are optional, so we need to check for them\n",
    "                if k in item:\n",
    "                    gf_item[k] = item.pop(k)\n",
    "                else:\n",
    "                    # helpful debugging message\n",
    "                    print(f\"Warning: {k} not found in item\")\n",
    "            gf_items.append(gf_item)\n",
    "\n",
    "\n",
    "        # custom call stuff for MassFormer\n",
    "        gf_collated = super().__call__(gf_items)\n",
    "        print(f\"gf_collated_keys = {list(gf_collated.keys())}\")\n",
    "\n",
    "        # After collating gf aspects, remove gf-related keys for mass spec collation\n",
    "        for item in items:\n",
    "            for k in gf_related_keys:\n",
    "                # note: some keys are optional, so we need to check for them\n",
    "                if k in item:\n",
    "                    item.pop(k)\n",
    "                else:\n",
    "                    print(f\"Warning: {k} not found in item\")\n",
    "\n",
    "        # now, let's handle the rest of the stuff\n",
    "        other_collated = {k: [] for k in items[0].keys()}\n",
    "        for data_d in items:\n",
    "            for k, v in data_d.items():\n",
    "                    other_collated[k].append(v)\n",
    "        for k, v in other_collated.items():\n",
    "            if isinstance(items[0][k], th.Tensor):\n",
    "                other_collated[k] = th.cat(v, dim=0)\n",
    "            elif isinstance(items[0][k], list):\n",
    "                other_collated[k] = utils.flatten_lol(v)\n",
    "            else:\n",
    "                raise ValueError(f\"{type(items[0][k])} is not supported\")\n",
    "\n",
    "        print(f\"other_collated_keys = {list(other_collated.keys())}\")\n",
    "\n",
    "        # now, let's combine the two collated dicts\n",
    "        both_collated = {**gf_collated, **other_collated}\n",
    "\n",
    "        return both_collated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainSubset(th_data.Subset):\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset.__getitem__(self.indices[idx])\n",
    "    \n",
    "class BaseDataset(th_data.Dataset):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        for k, v in kwargs.items():\n",
    "            setattr(self, k, v)\n",
    "        assert os.path.isdir(self.proc_dp), self.proc_dp\n",
    "        self.spec_df = pd.read_pickle(\n",
    "            os.path.join(self.proc_dp, \"spec_df.pkl\"))\n",
    "        self.mol_df = pd.read_pickle(\n",
    "            os.path.join(self.proc_dp, \"mol_df.pkl\"))\n",
    "        self.mol_df = self.mol_df[self.mol_df[\"mol_id\"].isin(self.spec_df[\"mol_id\"])]\n",
    "\n",
    "        # generate toy spec and mol df for faster processing\n",
    "        self.toy_spec_df = self.spec_df.sample(n=1000, replace=False, random_state=420)\n",
    "        self.toy_mol_df = self.mol_df[self.mol_df[\"mol_id\"].isin(self.toy_spec_df[\"mol_id\"])]\n",
    "\n",
    "        # save toy spec and mol df as pickle\n",
    "        self.toy_spec_df.to_pickle(\"data/proc_demo/toy_spec_df.pkl\")\n",
    "        self.toy_mol_df.to_pickle(\"data/proc_demo/toy_mol_df.pkl\")\n",
    "\n",
    "        # use toy df\n",
    "        self.spec_df = self.toy_spec_df\n",
    "        self.mol_df = self.toy_mol_df\n",
    "\n",
    "\n",
    "        self._select_spec()\n",
    "        self._setup_spec_metadata_dicts()\n",
    "        # use mol_id as index for speedy access\n",
    "        self.mol_df = self.mol_df.set_index(\n",
    "            \"mol_id\", drop=False).sort_index().rename_axis(None)\n",
    "\n",
    "        # spec_df = pd.read_pickle(\"data/proc_demo/spec_df.pkl\")\n",
    "        # mol_df = pd.read_pickle(\"data/proc_demo/mol_df.pkl\")\n",
    "        # toy_spec_df = spec_df.sample(n=1000, replace=False, random_state=420)\n",
    "        # toy_mol_df = mol_df[mol_df[\"mol_id\"].isin(toy_spec_df[\"mol_id\"])]\n",
    "        # toy_spec_df.to_pickle(\"data/proc_demo/toy_spec_df.pkl\")\n",
    "        # toy_mol_df.to_pickle(\"data/proc_demo/toy_mol_df.pkl\")\n",
    "        # toy_mol_df = toy_mol_df.set_index(\n",
    "        #             \"mol_id\", drop=False).sort_index().rename_axis(None)\n",
    "\n",
    "    def _select_spec(self):\n",
    "\n",
    "        masks = []\n",
    "        # dataset mask\n",
    "        dset_mask = self.spec_df[\"dset\"].isin(\n",
    "            self.primary_dset + self.secondary_dset)\n",
    "        masks.append(dset_mask)\n",
    "        # instrument type\n",
    "        inst_type_mask = self.spec_df[\"inst_type\"].isin(self.inst_type)\n",
    "        masks.append(inst_type_mask)\n",
    "        # frag mode\n",
    "        frag_mode_mask = self.spec_df[\"frag_mode\"].isin(self.frag_mode)\n",
    "        masks.append(frag_mode_mask)\n",
    "        # ion mode\n",
    "        ion_mode_mask = self.spec_df[\"ion_mode\"] == self.ion_mode\n",
    "        masks.append(ion_mode_mask)\n",
    "        # precursor type\n",
    "        if self.ion_mode == \"P\":\n",
    "            prec_type_mask = self.spec_df[\"prec_type\"].isin(self.pos_prec_type)\n",
    "        elif self.ion_mode == \"N\":\n",
    "            prec_type_mask = self.spec_df[\"prec_type\"].isin(self.neg_prec_type)\n",
    "        else:\n",
    "            assert self.ion_mode == \"EI\"\n",
    "            prec_type_mask = self.spec_df[\"prec_type\"] == \"EI\"\n",
    "        masks.append(prec_type_mask)\n",
    "        # resolution\n",
    "        if self.res != []:\n",
    "            res_mask = self.spec_df[\"res\"].isin(self.res)\n",
    "            masks.append(res_mask)\n",
    "        # collision energy\n",
    "        ce_mask = ~(self.spec_df[\"ace\"].isna() & self.spec_df[\"nce\"].isna())\n",
    "        masks.append(ce_mask)\n",
    "        # spectrum type\n",
    "        if self.ion_mode == \"EI\":\n",
    "            spec_type_mask = self.spec_df[\"spec_type\"] == \"EI\"\n",
    "        else:\n",
    "            spec_type_mask = self.spec_df[\"spec_type\"] == \"MS2\"\n",
    "        masks.append(spec_type_mask)\n",
    "        # maximum mz allowed\n",
    "        mz_mask = self.spec_df[\"peaks\"].apply(\n",
    "            lambda peaks: max(peak[0] for peak in peaks) < self.mz_max)\n",
    "        masks.append(mz_mask)\n",
    "        # precursor mz\n",
    "        prec_mz_mask = ~self.spec_df[\"prec_mz\"].isna()\n",
    "        masks.append(prec_mz_mask)\n",
    "        # single molecule\n",
    "        multi_mol_ids = self.mol_df[self.mol_df[\"smiles\"].str.contains(\n",
    "            \"\\\\.\")][\"mol_id\"]\n",
    "        single_mol_mask = ~self.spec_df[\"mol_id\"].isin(multi_mol_ids)\n",
    "        masks.append(single_mol_mask)\n",
    "        # neutral molecule\n",
    "        charges = self.mol_df[\"mol\"].apply(utils.mol_to_charge)\n",
    "        charged_ids = self.mol_df[charges != 0][\"mol_id\"]\n",
    "        neutral_mask = ~self.spec_df[\"mol_id\"].isin(charged_ids)\n",
    "        # print(neutral_mask.sum())\n",
    "        masks.append(neutral_mask)\n",
    "        # put them together\n",
    "        all_mask = masks[0]\n",
    "        for mask in masks:\n",
    "            all_mask = all_mask & mask\n",
    "        if np.sum(all_mask) == 0:\n",
    "            raise ValueError(\"select removed all items\")\n",
    "        self.spec_df = self.spec_df[all_mask].reset_index(drop=True)\n",
    "        self._setup_ce()\n",
    "        # get group_id\n",
    "        n_before_group = self.spec_df.shape[0]\n",
    "        group_df = self.spec_df.drop(\n",
    "            columns=[\n",
    "                \"spec_id\",\n",
    "                \"peaks\",\n",
    "                \"nce\",\n",
    "                \"ace\",\n",
    "                \"res\",\n",
    "                \"prec_mz\",\n",
    "                \"ri\",\n",
    "                \"col_gas\"])\n",
    "        assert not group_df.isna().any().any()\n",
    "        group_df = group_df.drop_duplicates()\n",
    "        group_df.loc[:, \"group_id\"] = np.arange(group_df.shape[0])\n",
    "        self.spec_df = self.spec_df.merge(group_df, how=\"inner\")\n",
    "        del group_df\n",
    "        n_after_group = self.spec_df.shape[0]\n",
    "        assert n_before_group == n_after_group\n",
    "        # compute stats\n",
    "        for dset in self.primary_dset + self.secondary_dset:\n",
    "            dset_spec_df = self.spec_df[self.spec_df[\"dset\"] == dset]\n",
    "            num_specs = dset_spec_df[\"spec_id\"].nunique()\n",
    "            num_mols = dset_spec_df[\"mol_id\"].nunique()\n",
    "            num_groups = dset_spec_df[\"group_id\"].nunique()\n",
    "            num_ces_per_group = dset_spec_df[[\"group_id\", self.ce_key]].groupby(\n",
    "                by=\"group_id\").count()[self.ce_key].mean()\n",
    "            print(f\">>> {dset}\")\n",
    "            print(\n",
    "                f\"> num_spec = {num_specs}, num_mol = {num_mols}, num_group = {num_groups}, num_ce_per_group = {num_ces_per_group}\")\n",
    "        # subsample\n",
    "        if self.subsample_size > 0:\n",
    "            self.spec_df = self.spec_df.groupby(\"mol_id\").sample(\n",
    "                n=self.subsample_size, random_state=self.subsample_seed, replace=True)\n",
    "            self.spec_df = self.spec_df.reset_index(drop=True)\n",
    "        else:\n",
    "            self.spec_df = self.spec_df\n",
    "        # num_entries\n",
    "        if self.num_entries > 0:\n",
    "            self.spec_df = self.spec_df.sample(\n",
    "                n=self.num_entries,\n",
    "                random_state=self.subsample_seed,\n",
    "                replace=False)\n",
    "            self.spec_df = self.spec_df.reset_index(drop=True)\n",
    "        # only keep mols with spectra\n",
    "        self.mol_df = self.mol_df[self.mol_df[\"mol_id\"].isin(\n",
    "            self.spec_df[\"mol_id\"])]\n",
    "        self.mol_df = self.mol_df.reset_index(drop=True)\n",
    "\n",
    "    def _setup_ce(self):\n",
    "\n",
    "        if self.convert_ce:\n",
    "            if self.ce_key == \"ace\":\n",
    "                other_ce_key = \"nce\"\n",
    "                ce_conversion_fn = utils.nce_to_ace\n",
    "            else:\n",
    "                other_ce_key = \"ace\"\n",
    "                ce_conversion_fn = utils.ace_to_nce\n",
    "            convert_mask = self.spec_df[self.ce_key].isna()\n",
    "            assert not self.spec_df.loc[convert_mask,\n",
    "                                        other_ce_key].isna().any()\n",
    "            self.spec_df.loc[convert_mask, self.ce_key] = self.spec_df[convert_mask].apply(\n",
    "                ce_conversion_fn, axis=1)\n",
    "            assert not self.spec_df[self.ce_key].isna().any()\n",
    "        else:\n",
    "            self.spec_df = self.spec_df.dropna(\n",
    "                axis=0, subset=[\n",
    "                    self.ce_key]).reset_index(\n",
    "                drop=True)\n",
    "\n",
    "    def _setup_spec_metadata_dicts(self):\n",
    "\n",
    "        # featurize spectral metadata\n",
    "        # we can assume that the dataset is filtered (using the method above)\n",
    "        # to only include these values\n",
    "        inst_type_list = self.inst_type\n",
    "        if self.ion_mode == \"P\":\n",
    "            prec_type_list = self.pos_prec_type\n",
    "        elif self.ion_mode == \"N\":\n",
    "            prec_type_list = self.neg_prec_type\n",
    "        else:\n",
    "            assert self.ion_mode == \"EI\"\n",
    "            prec_type_list = [\"EI\"]\n",
    "        frag_mode_list = self.frag_mode\n",
    "        self.inst_type_c2i = {\n",
    "            string: i for i,\n",
    "            string in enumerate(inst_type_list)}\n",
    "        self.inst_type_i2c = {\n",
    "            i: string for i,\n",
    "            string in enumerate(inst_type_list)}\n",
    "        self.prec_type_c2i = {\n",
    "            string: i for i,\n",
    "            string in enumerate(prec_type_list)}\n",
    "        self.prec_type_i2c = {\n",
    "            i: string for i,\n",
    "            string in enumerate(prec_type_list)}\n",
    "        self.frag_mode_c2i = {\n",
    "            string: i for i,\n",
    "            string in enumerate(frag_mode_list)}\n",
    "        self.frag_mode_i2c = {\n",
    "            i: string for i,\n",
    "            string in enumerate(frag_mode_list)}\n",
    "        self.num_inst_type = len(inst_type_list)\n",
    "        self.num_prec_type = len(prec_type_list)\n",
    "        self.num_frag_mode = len(frag_mode_list)\n",
    "        self.max_ce = self.spec_df[self.ce_key].max()\n",
    "        self.mean_ce = self.spec_df[self.ce_key].mean()\n",
    "        self.std_ce = self.spec_df[self.ce_key].std()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        spec_entry = self.spec_df.iloc[idx]\n",
    "        mol_id = spec_entry[\"mol_id\"]\n",
    "        # mol_entry = self.mol_df[self.mol_df[\"mol_id\"] == mol_id].iloc[0]\n",
    "        mol_entry = self.mol_df.loc[mol_id]\n",
    "        data = self.process_entry(spec_entry, mol_entry[\"mol\"])\n",
    "        return data\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return self.spec_df.shape[0]\n",
    "\n",
    "    def bin_func(self, mzs, ints, return_index=False):\n",
    "\n",
    "        assert self.ints_thresh == 0., self.ints_thresh\n",
    "        return utils.bin_func(\n",
    "            mzs,\n",
    "            ints,\n",
    "            self.mz_max,\n",
    "            self.mz_bin_res,\n",
    "            self.ints_thresh,\n",
    "            return_index)\n",
    "\n",
    "    def transform_func(self, spec):\n",
    "\n",
    "        if self.process_spec_old:\n",
    "            spec = utils.process_spec_old(\n",
    "                spec,\n",
    "                self.transform,\n",
    "                self.spectrum_normalization,\n",
    "                self.ints_thresh)\n",
    "        else:\n",
    "            spec = utils.process_spec(\n",
    "                th.as_tensor(spec),\n",
    "                self.transform,\n",
    "                self.spectrum_normalization)\n",
    "            spec = spec.numpy()\n",
    "        return spec\n",
    "\n",
    "    def get_split_masks(\n",
    "            self,\n",
    "            val_frac,\n",
    "            test_frac,\n",
    "            sec_frac,\n",
    "            split_key,\n",
    "            split_seed,\n",
    "            ignore_casmi):\n",
    "\n",
    "        assert split_key in [\"inchikey_s\", \"scaffold\"], split_key\n",
    "        assert len(self.secondary_dset) <= 1, self.secondary_dset\n",
    "        # primary\n",
    "        prim_mask = self.spec_df[\"dset\"].isin(self.primary_dset)\n",
    "        prim_mol_id = self.spec_df[prim_mask][\"mol_id\"].unique()\n",
    "        prim_key = set(\n",
    "            self.mol_df[self.mol_df[\"mol_id\"].isin(prim_mol_id)][split_key])\n",
    "        # secondary\n",
    "        sec_mask = self.spec_df[\"dset\"].isin(self.secondary_dset)\n",
    "        sec_mol_id = self.spec_df[sec_mask][\"mol_id\"].unique()\n",
    "        sec_key = set(\n",
    "            self.mol_df[self.mol_df[\"mol_id\"].isin(sec_mol_id)][split_key])\n",
    "        sec_key_list = sorted(list(sec_key))\n",
    "        # print(sec_key_list[:5])\n",
    "        # sample secondary keys\n",
    "        with utils.np_temp_seed(split_seed):\n",
    "            sec_num = round(len(sec_key_list) * sec_frac)\n",
    "            sec_key_list = np.random.choice(\n",
    "                sec_key_list, size=sec_num, replace=False).tolist()\n",
    "            sec_key = set(sec_key_list)\n",
    "            # print(sec_key_list[:5])\n",
    "            sec_mol_id = self.mol_df[self.mol_df[split_key].isin(\n",
    "                sec_key_list) & self.mol_df[\"mol_id\"].isin(sec_mol_id)][\"mol_id\"].unique()\n",
    "            sec_mask = self.spec_df[\"mol_id\"].isin(sec_mol_id) & sec_mask\n",
    "            # print(split_seed,sec_num,sec_mask.sum())\n",
    "        # get keys (secondary might same compounds as primary does!)\n",
    "        prim_only_key = prim_key - sec_key\n",
    "        sec_only_key = sec_key\n",
    "        prim_only_key_list = sorted(list(prim_only_key))\n",
    "        both_key = prim_key & sec_key\n",
    "        # compute number for each split\n",
    "        test_num = round(len(prim_only_key_list) * test_frac)\n",
    "        val_num = round(len(prim_only_key_list) * val_frac)\n",
    "        # make sure that test set gets all of the casmi keys!\n",
    "        if not ignore_casmi:\n",
    "            prim_only_and_casmi = prim_only_key & self.casmi_info[split_key]\n",
    "        else:\n",
    "            prim_only_and_casmi = set()\n",
    "        if test_num > 0:\n",
    "            assert len(prim_only_and_casmi) <= test_num\n",
    "            test_num -= len(prim_only_and_casmi)\n",
    "        prim_only_no_casmi_key_list = [\n",
    "            k for k in prim_only_key_list if not (\n",
    "                k in prim_only_and_casmi)]\n",
    "        assert len(set(prim_only_no_casmi_key_list) & prim_only_and_casmi) == 0\n",
    "        # do the split\n",
    "        with utils.np_temp_seed(split_seed):\n",
    "            prim_only_test_num = max(test_num - len(both_key), 0)\n",
    "            test_key = set(\n",
    "                np.random.choice(\n",
    "                    prim_only_no_casmi_key_list,\n",
    "                    size=prim_only_test_num,\n",
    "                    replace=False))\n",
    "            test_key = test_key.union(prim_only_and_casmi).union(both_key)\n",
    "            train_val_key = prim_only_key - test_key\n",
    "            val_key = set(\n",
    "                np.random.choice(\n",
    "                    sorted(\n",
    "                        list(train_val_key)),\n",
    "                    size=val_num,\n",
    "                    replace=False))\n",
    "            train_key = train_val_key - val_key\n",
    "            assert len(train_key & sec_only_key) == 0\n",
    "            assert len(val_key & sec_only_key) == 0\n",
    "            # assert len(test_key & sec_only_key) == 0\n",
    "            assert len(train_key & prim_only_and_casmi) == 0\n",
    "            assert len(val_key & prim_only_and_casmi) == 0\n",
    "        # get ids and create masks\n",
    "        train_mol_id = self.mol_df[\"mol_id\"][self.mol_df[split_key].isin(\n",
    "            list(train_key))].unique()\n",
    "        val_mol_id = self.mol_df[\"mol_id\"][self.mol_df[split_key].isin(\n",
    "            list(val_key))].unique()\n",
    "        test_mol_id = self.mol_df[\"mol_id\"][self.mol_df[split_key].isin(\n",
    "            list(test_key))].unique()\n",
    "        train_mask = self.spec_df[\"mol_id\"].isin(train_mol_id)\n",
    "        val_mask = self.spec_df[\"mol_id\"].isin(val_mol_id)\n",
    "        test_mask = self.spec_df[\"mol_id\"].isin(test_mol_id)\n",
    "        prim_mask = train_mask | val_mask | test_mask\n",
    "        prim_mol_id = pd.Series(\n",
    "            list(set(train_mol_id) | set(val_mol_id) | set(test_mol_id)))\n",
    "        # note: primary can include secondary molecules in the test split\n",
    "        sec_masks = [(self.spec_df[\"dset\"] == dset) & (\n",
    "            self.spec_df[\"mol_id\"].isin(sec_mol_id)) for dset in self.secondary_dset]\n",
    "        assert (train_mask & val_mask & test_mask).sum() == 0\n",
    "        print(\"> primary\")\n",
    "        print(\"splits: train, val, test, total\")\n",
    "        print(\n",
    "            f\"spec: {train_mask.sum()}, {val_mask.sum()}, {test_mask.sum()}, {prim_mask.sum()}\")\n",
    "        print(\n",
    "            f\"mol: {len(train_mol_id)}, {len(val_mol_id)}, {len(test_mol_id)}, {len(prim_mol_id)}\")\n",
    "        if len(self.secondary_dset) > 0:\n",
    "            print(\"> secondary\")\n",
    "        for sec_idx, sec_dset in enumerate(self.secondary_dset):\n",
    "            cur_sec = self.spec_df[sec_masks[sec_idx]]\n",
    "            cur_sec_mol_id = cur_sec[\"mol_id\"]\n",
    "            cur_both_mol_mask = self.spec_df[\"mol_id\"].isin(\n",
    "                set(prim_mol_id) & set(cur_sec_mol_id))\n",
    "            cur_prim_both = self.spec_df[prim_mask & cur_both_mol_mask]\n",
    "            cur_sec_both = self.spec_df[sec_masks[sec_idx] & cur_both_mol_mask]\n",
    "            print(\n",
    "                f\"{sec_dset} spec = {cur_sec.shape[0]}, mol = {cur_sec_mol_id.nunique()}\")\n",
    "            print(\n",
    "                f\"{sec_dset} overlap: prim spec = {cur_prim_both.shape[0]}, sec spec = {cur_sec_both.shape[0]}, mol = {cur_prim_both['mol_id'].nunique()}\")\n",
    "        return train_mask, val_mask, test_mask, sec_masks\n",
    "\n",
    "    def get_spec_feats(self, spec_entry):\n",
    "\n",
    "        # convert to a dense vector\n",
    "        mol_id = th.tensor(spec_entry[\"mol_id\"]).unsqueeze(0)\n",
    "        spec_id = th.tensor(spec_entry[\"spec_id\"]).unsqueeze(0)\n",
    "        group_id = th.tensor(spec_entry[\"group_id\"]).unsqueeze(0)\n",
    "        mzs = [peak[0] for peak in spec_entry[\"peaks\"]]\n",
    "        ints = [peak[1] for peak in spec_entry[\"peaks\"]]\n",
    "        prec_mz = spec_entry[\"prec_mz\"]\n",
    "        prec_mz_bin = self.bin_func([prec_mz], None, return_index=True)[0]\n",
    "        prec_diff = max(mz - prec_mz for mz in mzs)\n",
    "        num_peaks = len(mzs)\n",
    "        bin_spec = self.transform_func(self.bin_func(mzs, ints))\n",
    "        spec = th.as_tensor(bin_spec, dtype=th.float32).unsqueeze(0)\n",
    "        col_energy = spec_entry[self.ce_key]\n",
    "        inst_type = spec_entry[\"inst_type\"]\n",
    "        prec_type = spec_entry[\"prec_type\"]\n",
    "        frag_mode = spec_entry[\"frag_mode\"]\n",
    "        charge = utils.get_charge(prec_type)\n",
    "        inst_type_idx = self.inst_type_c2i[inst_type]\n",
    "        prec_type_idx = self.prec_type_c2i[prec_type]\n",
    "        frag_mode_idx = self.frag_mode_c2i[frag_mode]\n",
    "        # same as prec_mz_bin but tensor\n",
    "        prec_mz_idx = th.tensor(\n",
    "            min(prec_mz_bin, spec.shape[1] - 1)).unsqueeze(0)\n",
    "        assert prec_mz_idx < spec.shape[1], (prec_mz_bin,\n",
    "                                             prec_mz_idx, spec.shape)\n",
    "        if self.preproc_ce == \"normalize\":\n",
    "            col_energy_meta = th.tensor(\n",
    "                [(col_energy - self.mean_ce) / (self.std_ce + utils.EPS)], dtype=th.float32)\n",
    "        elif self.preproc_ce == \"quantize\":\n",
    "            ce_bins = np.arange(0, 161, step=20)  # 8 bins\n",
    "            ce_idx = np.digitize(col_energy, bins=ce_bins, right=False)\n",
    "            col_energy_meta = th.ones([len(ce_bins) + 1], dtype=th.float32)\n",
    "            col_energy_meta[ce_idx] = 1.\n",
    "        else:\n",
    "            assert self.preproc_ce == \"none\", self.preproc_ce\n",
    "            col_energy_meta = th.tensor([col_energy], dtype=th.float32)\n",
    "        inst_type_meta = th.as_tensor(\n",
    "            utils.np_one_hot(\n",
    "                inst_type_idx,\n",
    "                num_classes=self.num_inst_type),\n",
    "            dtype=th.float32)\n",
    "        prec_type_meta = th.as_tensor(\n",
    "            utils.np_one_hot(\n",
    "                prec_type_idx,\n",
    "                num_classes=self.num_prec_type),\n",
    "            dtype=th.float32)\n",
    "        frag_mode_meta = th.as_tensor(\n",
    "            utils.np_one_hot(\n",
    "                frag_mode_idx,\n",
    "                num_classes=self.num_frag_mode),\n",
    "            dtype=th.float32)\n",
    "        spec_meta_list = [\n",
    "            col_energy_meta,\n",
    "            inst_type_meta,\n",
    "            prec_type_meta,\n",
    "            frag_mode_meta,\n",
    "            col_energy_meta]\n",
    "        spec_meta = th.cat(spec_meta_list, dim=0).unsqueeze(0)\n",
    "        spec_feats = {\n",
    "            \"spec\": spec,\n",
    "            \"prec_mz\": [prec_mz],\n",
    "            \"prec_mz_bin\": [prec_mz_bin],\n",
    "            \"prec_diff\": [prec_diff],\n",
    "            \"num_peaks\": [num_peaks],\n",
    "            \"inst_type\": [inst_type],\n",
    "            \"prec_type\": [prec_type],\n",
    "            \"frag_mode\": [frag_mode],\n",
    "            \"col_energy\": [col_energy],\n",
    "            \"charge\": [charge],\n",
    "            \"spec_meta\": spec_meta,\n",
    "            \"mol_id\": mol_id,\n",
    "            \"spec_id\": spec_id,\n",
    "            \"group_id\": group_id,\n",
    "            \"prec_mz_idx\": prec_mz_idx\n",
    "        }\n",
    "        if \"casmi_id\" in spec_entry:\n",
    "            spec_feats[\"casmi_id\"] = th.tensor(\n",
    "                spec_entry[\"casmi_id\"]).unsqueeze(0)\n",
    "        if \"lda_topic\" in spec_entry:\n",
    "            spec_feats[\"lda_topic\"] = th.tensor(\n",
    "                spec_entry[\"lda_topic\"]).unsqueeze(0)\n",
    "        return spec_feats\n",
    "\n",
    "    def get_dataloaders(self, run_d):\n",
    "\n",
    "        val_frac = run_d[\"val_frac\"]\n",
    "        test_frac = run_d[\"test_frac\"]\n",
    "        sec_frac = run_d[\"sec_frac\"]\n",
    "        split_key = run_d[\"split_key\"]\n",
    "        split_seed = run_d[\"split_seed\"]\n",
    "        ignore_casmi = run_d[\"ignore_casmi_in_split\"]\n",
    "        assert run_d[\"batch_size\"] % run_d[\"grad_acc_interval\"] == 0\n",
    "        batch_size = run_d[\"batch_size\"] // run_d[\"grad_acc_interval\"]\n",
    "        num_workers = run_d[\"num_workers\"]\n",
    "        pin_memory = run_d[\"pin_memory\"] if run_d[\"device\"] != \"cpu\" else False\n",
    "\n",
    "        train_mask, val_mask, test_mask, sec_masks = self.get_split_masks(\n",
    "            val_frac, test_frac, sec_frac, split_key, split_seed, ignore_casmi)\n",
    "        all_idx = np.arange(len(self))\n",
    "        # th_data.RandomSampler()\n",
    "        train_ss = TrainSubset(self, all_idx[train_mask])\n",
    "        # th_data.RandomSampler(th_data.Subset(self,all_idx[val_mask]))\n",
    "        val_ss = th_data.Subset(self, all_idx[val_mask])\n",
    "        # th_data.RandomSampler(th_data.Subset(self,all_idx[test_mask]))\n",
    "        test_ss = th_data.Subset(self, all_idx[test_mask])\n",
    "        sec_ss = [th_data.Subset(self, all_idx[sec_mask])\n",
    "                  for sec_mask in sec_masks]\n",
    "\n",
    "        collate_fn = self.get_collate_fn()\n",
    "        if len(train_ss) > 0:\n",
    "            train_dl = th_data.DataLoader(\n",
    "                train_ss,\n",
    "                batch_size=batch_size,\n",
    "                collate_fn=collate_fn,\n",
    "                num_workers=num_workers,\n",
    "                pin_memory=pin_memory,\n",
    "                shuffle=True,\n",
    "                drop_last=True  # this is to prevent single data batches that mess with batchnorm\n",
    "            )\n",
    "            train_dl_2 = th_data.DataLoader(\n",
    "                train_ss,\n",
    "                batch_size=batch_size,\n",
    "                collate_fn=collate_fn,\n",
    "                num_workers=num_workers,\n",
    "                pin_memory=pin_memory,\n",
    "                shuffle=False,\n",
    "                drop_last=False\n",
    "            )\n",
    "        else:\n",
    "            train_dl = train_dl_2 = None\n",
    "        if len(val_ss) > 0:\n",
    "            val_dl = th_data.DataLoader(\n",
    "                val_ss,\n",
    "                batch_size=batch_size,\n",
    "                collate_fn=collate_fn,\n",
    "                num_workers=num_workers,\n",
    "                pin_memory=pin_memory,\n",
    "                shuffle=False,\n",
    "                drop_last=False\n",
    "            )\n",
    "        else:\n",
    "            val_dl = None\n",
    "        if len(test_ss) > 0:\n",
    "            test_dl = th_data.DataLoader(\n",
    "                test_ss,\n",
    "                batch_size=batch_size,\n",
    "                collate_fn=collate_fn,\n",
    "                num_workers=num_workers,\n",
    "                pin_memory=pin_memory,\n",
    "                shuffle=False,\n",
    "                drop_last=False\n",
    "            )\n",
    "        else:\n",
    "            test_dl = None\n",
    "        sec_dls = []\n",
    "        for ss in sec_ss:\n",
    "            dl = th_data.DataLoader(\n",
    "                ss,\n",
    "                batch_size=batch_size,\n",
    "                collate_fn=collate_fn,\n",
    "                num_workers=num_workers,\n",
    "                pin_memory=pin_memory,\n",
    "                shuffle=False,\n",
    "                drop_last=False\n",
    "            )\n",
    "            sec_dls.append(dl)\n",
    "\n",
    "        # set up dl_dict\n",
    "        dl_dict = {}\n",
    "        dl_dict[\"train\"] = train_dl\n",
    "        dl_dict[\"primary\"] = {\n",
    "            \"train\": train_dl_2,\n",
    "            \"val\": val_dl,\n",
    "            \"test\": test_dl\n",
    "        }\n",
    "        dl_dict[\"secondary\"] = {}\n",
    "        for sec_idx, sec_dset in enumerate(self.secondary_dset):\n",
    "            dl_dict[\"secondary\"][f\"{sec_dset}\"] = sec_dls[sec_idx]\n",
    "\n",
    "        # set up split_id_dict\n",
    "        split_id_dict = {}\n",
    "        split_id_dict[\"primary\"] = {}\n",
    "        split_id_dict[\"primary\"][\"train\"] = self.spec_df.iloc[all_idx[train_mask]\n",
    "                                                              ][\"spec_id\"].to_numpy()\n",
    "        split_id_dict[\"primary\"][\"val\"] = self.spec_df.iloc[all_idx[val_mask]\n",
    "                                                            ][\"spec_id\"].to_numpy()\n",
    "        split_id_dict[\"primary\"][\"test\"] = self.spec_df.iloc[all_idx[test_mask]\n",
    "                                                             ][\"spec_id\"].to_numpy()\n",
    "        split_id_dict[\"secondary\"] = {}\n",
    "        for sec_idx, sec_dset in enumerate(self.secondary_dset):\n",
    "            split_id_dict[\"secondary\"][sec_dset] = self.spec_df.iloc[all_idx[sec_masks[sec_idx]]\n",
    "                                                                     ][\"spec_id\"].to_numpy()\n",
    "\n",
    "        return dl_dict, split_id_dict\n",
    "\n",
    "    def get_track_dl(\n",
    "            self,\n",
    "            idx,\n",
    "            num_rand_idx=0,\n",
    "            topk_idx=None,\n",
    "            bottomk_idx=None,\n",
    "            other_idx=None,\n",
    "            spec_ids=None):\n",
    "\n",
    "        track_seed = 5585\n",
    "        track_dl_dict = {}\n",
    "        collate_fn = self.get_collate_fn()\n",
    "        if num_rand_idx > 0:\n",
    "            with utils.np_temp_seed(track_seed):\n",
    "                rand_idx = np.random.choice(\n",
    "                    idx, size=num_rand_idx, replace=False)\n",
    "            rand_dl = th_data.DataLoader(\n",
    "                th_data.Subset(self, rand_idx),\n",
    "                batch_size=1,\n",
    "                collate_fn=collate_fn,\n",
    "                num_workers=0,\n",
    "                pin_memory=False,\n",
    "                shuffle=False,\n",
    "                drop_last=False\n",
    "            )\n",
    "            track_dl_dict[\"rand\"] = rand_dl\n",
    "        if not (topk_idx is None):\n",
    "            topk_idx = idx[topk_idx]\n",
    "            topk_dl = th_data.DataLoader(\n",
    "                th_data.Subset(self, topk_idx),\n",
    "                batch_size=1,\n",
    "                collate_fn=collate_fn,\n",
    "                num_workers=0,\n",
    "                pin_memory=False,\n",
    "                shuffle=False,\n",
    "                drop_last=False\n",
    "            )\n",
    "            track_dl_dict[\"topk\"] = topk_dl\n",
    "        if not (bottomk_idx is None):\n",
    "            bottomk_idx = idx[bottomk_idx]\n",
    "            bottomk_dl = th_data.DataLoader(\n",
    "                th_data.Subset(self, bottomk_idx),\n",
    "                batch_size=1,\n",
    "                collate_fn=collate_fn,\n",
    "                num_workers=0,\n",
    "                pin_memory=False,\n",
    "                shuffle=False,\n",
    "                drop_last=False\n",
    "            )\n",
    "            track_dl_dict[\"bottomk\"] = bottomk_dl\n",
    "        if not (other_idx is None):\n",
    "            other_idx = idx[other_idx]\n",
    "            other_dl = th_data.DataLoader(\n",
    "                th_data.Subset(self, other_idx),\n",
    "                batch_size=1,\n",
    "                collate_fn=collate_fn,\n",
    "                num_workers=0,\n",
    "                pin_memory=False,\n",
    "                shuffle=False,\n",
    "                drop_last=False\n",
    "            )\n",
    "            track_dl_dict[\"other\"] = other_dl\n",
    "        if not (spec_ids is None):\n",
    "            # preserves order\n",
    "            spec_idx = []\n",
    "            for spec_id in spec_ids:\n",
    "                spec_idx.append(\n",
    "                    int(self.spec_df[self.spec_df[\"spec_id\"] == spec_id].index[0]))\n",
    "            spec_idx = np.array(spec_idx)\n",
    "            spec_dl = th_data.DataLoader(\n",
    "                th_data.Subset(self, spec_idx),\n",
    "                batch_size=1,\n",
    "                collate_fn=collate_fn,\n",
    "                num_workers=0,\n",
    "                pin_memory=False,\n",
    "                shuffle=False,\n",
    "                drop_last=False\n",
    "            )\n",
    "            track_dl_dict[\"spec\"] = spec_dl\n",
    "        return track_dl_dict\n",
    "\n",
    " \n",
    "    def get_data_dims(self):\n",
    "\n",
    "        data = self.__getitem__(0)\n",
    "        dim_d = {}\n",
    "        if self.is_fp_dset:\n",
    "            fp_dim = data[\"fp\"].shape[1]\n",
    "        else:\n",
    "            fp_dim = -1\n",
    "        if self.is_graph_dset:\n",
    "            # node\n",
    "            if self.atom_feature_mode == \"pretrain\":\n",
    "                n_dim = -1\n",
    "            else:\n",
    "                n_dim = data[\"graph\"].ndata['h'].shape[1]\n",
    "            # edge\n",
    "            if self.bond_feature_mode == \"none\":\n",
    "                e_dim = 0\n",
    "            elif self.bond_feature_mode == \"pretrain\":\n",
    "                e_dim = -1\n",
    "            else:\n",
    "                e_dim = data[\"graph\"].edata['h'].shape[1]\n",
    "        else:\n",
    "            n_dim = e_dim = -1\n",
    "        c_dim = l_dim = -1\n",
    "        if self.spec_meta_global:\n",
    "            g_dim = data[\"spec_meta\"].shape[1]\n",
    "        else:\n",
    "            g_dim = 0  # -1\n",
    "        o_dim = data[\"spec\"].shape[1]\n",
    "        dim_d = {\n",
    "            \"fp_dim\": fp_dim,\n",
    "            \"n_dim\": n_dim,\n",
    "            \"e_dim\": e_dim,\n",
    "            \"c_dim\": c_dim,\n",
    "            \"l_dim\": l_dim,\n",
    "            \"g_dim\": g_dim,\n",
    "            \"o_dim\": o_dim\n",
    "        }\n",
    "        return dim_d\n",
    "\n",
    "    def get_collate_fn(self):\n",
    "        return MassFormerDataCollator()\n",
    "\n",
    "    def process_entry(self, spec_entry, mol):\n",
    "\n",
    "        # initialize data with shared attributes\n",
    "        spec_feats = self.get_spec_feats(spec_entry)\n",
    "        data_d = {**spec_feats}\n",
    "        data_d[\"smiles\"] = [utils.mol_to_smiles(mol)]\n",
    "        data_d[\"formula\"] = [utils.mol_to_formula(mol)]\n",
    "        graph = utils.mol2graph(mol)\n",
    "        data = utils.graph2data(graph)\n",
    "        items = preprocess_item(data)\n",
    "        data_d.update(items)\n",
    "        return data_d\n",
    "\n",
    "    def load_all(self, keys):\n",
    "\n",
    "        collate_fn = self.get_collate_fn()\n",
    "        dl = th_data.DataLoader(\n",
    "            self,\n",
    "            batch_size=100,\n",
    "            collate_fn=collate_fn,\n",
    "            num_workers=min(10, len(os.sched_getaffinity(0))),\n",
    "            pin_memory=False,\n",
    "            shuffle=False,\n",
    "            drop_last=False\n",
    "        )\n",
    "        all_ds = []\n",
    "        for b_idx, b in tqdm(enumerate(dl), total=len(dl), desc=\"> load_all\"):\n",
    "            b_d = {}\n",
    "            for k in keys:\n",
    "                b_d[k] = b[k]\n",
    "            all_ds.append(b_d)\n",
    "        all_d = collate_fn(all_ds)\n",
    "        return all_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> mb_na\n",
      "> num_spec = 99, num_mol = 93, num_group = 93, num_ce_per_group = 1.064516129032258\n"
     ]
    }
   ],
   "source": [
    "demo_dataset = BaseDataset(proc_dp=\"data/proc_demo/\", primary_dset=[\"mb_na\"], secondary_dset=[], \n",
    "                           ce_key=\"nce\", inst_type=[\"FT\"], frag_mode=[\"HCD\"], ion_mode=\"P\", process_spec_old=False,\n",
    "                           pos_prec_type=['[M+H]+', '[M+H-H2O]+', '[M+H-2H2O]+', '[M+2H]2+', '[M+H-NH3]+', \"[M+Na]+\"],\n",
    "                           preproc_ce=\"normalize\", mz_max=1000., convert_ce=False, subsample_size=0, num_entries=-1,\n",
    "                           spectrum_normalization=\"l1\", res=[1,2,3,4,5,6,7], mz_bin_res=1., ints_thresh=0., transform=\"log10over3\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all keys = ['spec', 'prec_mz', 'prec_mz_bin', 'prec_diff', 'num_peaks', 'inst_type', 'prec_type', 'frag_mode', 'col_energy', 'charge', 'spec_meta', 'mol_id', 'spec_id', 'group_id', 'prec_mz_idx', 'smiles', 'formula', 'spatial_pos', 'edge_index', 'input_edges', 'x', 'edge_attr', 'num_nodes', 'in_degree', 'out_degree', 'attn_bias', 'input_nodes', 'attn_edge_type', 'y', 'labels']\n",
      "gf_collated_keys = ['attn_bias', 'attn_edge_type', 'spatial_pos', 'in_degree', 'input_nodes', 'input_edges', 'out_degree', 'labels']\n",
      "Warning: spatial_pos not found in item\n",
      "Warning: labels not found in item\n",
      "Warning: attn_bias not found in item\n",
      "Warning: input_nodes not found in item\n",
      "Warning: attn_edge_type not found in item\n",
      "Warning: in_degree not found in item\n",
      "Warning: input_edges not found in item\n",
      "Warning: out_degree not found in item\n",
      "Warning: spatial_pos not found in item\n",
      "Warning: labels not found in item\n",
      "Warning: attn_bias not found in item\n",
      "Warning: input_nodes not found in item\n",
      "Warning: attn_edge_type not found in item\n",
      "Warning: in_degree not found in item\n",
      "Warning: input_edges not found in item\n",
      "Warning: out_degree not found in item\n",
      "other_collated_keys = ['spec', 'prec_mz', 'prec_mz_bin', 'prec_diff', 'num_peaks', 'inst_type', 'prec_type', 'frag_mode', 'col_energy', 'charge', 'spec_meta', 'mol_id', 'spec_id', 'group_id', 'prec_mz_idx', 'smiles', 'formula']\n",
      "{'attn_bias': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]]), 'attn_edge_type': tensor([[[[   0,    0,    0],\n",
      "          [   2,  514, 1026],\n",
      "          [   0,    0,    0],\n",
      "          ...,\n",
      "          [   0,    0,    0],\n",
      "          [   0,    0,    0],\n",
      "          [   0,    0,    0]],\n",
      "\n",
      "         [[   2,  514, 1026],\n",
      "          [   0,    0,    0],\n",
      "          [   2,  514, 1027],\n",
      "          ...,\n",
      "          [   0,    0,    0],\n",
      "          [   0,    0,    0],\n",
      "          [   0,    0,    0]],\n",
      "\n",
      "         [[   0,    0,    0],\n",
      "          [   2,  514, 1027],\n",
      "          [   0,    0,    0],\n",
      "          ...,\n",
      "          [   0,    0,    0],\n",
      "          [   0,    0,    0],\n",
      "          [   5,  514, 1027]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[   0,    0,    0],\n",
      "          [   0,    0,    0],\n",
      "          [   0,    0,    0],\n",
      "          ...,\n",
      "          [   0,    0,    0],\n",
      "          [   5,  514, 1027],\n",
      "          [   0,    0,    0]],\n",
      "\n",
      "         [[   0,    0,    0],\n",
      "          [   0,    0,    0],\n",
      "          [   0,    0,    0],\n",
      "          ...,\n",
      "          [   5,  514, 1027],\n",
      "          [   0,    0,    0],\n",
      "          [   5,  514, 1027]],\n",
      "\n",
      "         [[   0,    0,    0],\n",
      "          [   0,    0,    0],\n",
      "          [   5,  514, 1027],\n",
      "          ...,\n",
      "          [   0,    0,    0],\n",
      "          [   5,  514, 1027],\n",
      "          [   0,    0,    0]]],\n",
      "\n",
      "\n",
      "        [[[   0,    0,    0],\n",
      "          [   2,  514, 1026],\n",
      "          [   0,    0,    0],\n",
      "          ...,\n",
      "          [   0,    0,    0],\n",
      "          [   0,    0,    0],\n",
      "          [   0,    0,    0]],\n",
      "\n",
      "         [[   2,  514, 1026],\n",
      "          [   0,    0,    0],\n",
      "          [   2,  514, 1026],\n",
      "          ...,\n",
      "          [   0,    0,    0],\n",
      "          [   0,    0,    0],\n",
      "          [   0,    0,    0]],\n",
      "\n",
      "         [[   0,    0,    0],\n",
      "          [   2,  514, 1026],\n",
      "          [   0,    0,    0],\n",
      "          ...,\n",
      "          [   0,    0,    0],\n",
      "          [   0,    0,    0],\n",
      "          [   0,    0,    0]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[   0,    0,    0],\n",
      "          [   0,    0,    0],\n",
      "          [   0,    0,    0],\n",
      "          ...,\n",
      "          [   0,    0,    0],\n",
      "          [   0,    0,    0],\n",
      "          [   0,    0,    0]],\n",
      "\n",
      "         [[   0,    0,    0],\n",
      "          [   0,    0,    0],\n",
      "          [   0,    0,    0],\n",
      "          ...,\n",
      "          [   0,    0,    0],\n",
      "          [   0,    0,    0],\n",
      "          [   0,    0,    0]],\n",
      "\n",
      "         [[   0,    0,    0],\n",
      "          [   0,    0,    0],\n",
      "          [   0,    0,    0],\n",
      "          ...,\n",
      "          [   0,    0,    0],\n",
      "          [   0,    0,    0],\n",
      "          [   0,    0,    0]]]]), 'spatial_pos': tensor([[[1, 2, 3,  ..., 6, 5, 4],\n",
      "         [2, 1, 2,  ..., 5, 4, 3],\n",
      "         [3, 2, 1,  ..., 4, 3, 2],\n",
      "         ...,\n",
      "         [6, 5, 4,  ..., 1, 2, 3],\n",
      "         [5, 4, 3,  ..., 2, 1, 2],\n",
      "         [4, 3, 2,  ..., 3, 2, 1]],\n",
      "\n",
      "        [[1, 2, 3,  ..., 0, 0, 0],\n",
      "         [2, 1, 2,  ..., 0, 0, 0],\n",
      "         [3, 2, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]]]), 'in_degree': tensor([[2, 3, 4, 3, 4, 3, 2, 4, 3, 4, 5, 2, 2, 3, 4, 4, 2, 3, 3, 4, 2, 4, 2, 3,\n",
      "         4, 3],\n",
      "        [2, 3, 3, 4, 3, 3, 4, 3, 3, 3, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]]), 'input_nodes': tensor([[[4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4]],\n",
      "\n",
      "        [[4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [0],\n",
      "         [0],\n",
      "         [0],\n",
      "         [0],\n",
      "         [0],\n",
      "         [0],\n",
      "         [0],\n",
      "         [0],\n",
      "         [0],\n",
      "         [0],\n",
      "         [0],\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]]]), 'input_edges': tensor([[[[[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   3,  515, 1027],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   3,  515, 1027],\n",
      "           [   3,  515, 1028],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[   3,  515, 1027],\n",
      "           [   3,  515, 1028],\n",
      "           [   6,  515, 1028],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   3,  515, 1027],\n",
      "           [   3,  515, 1028],\n",
      "           [   6,  515, 1028],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   3,  515, 1027],\n",
      "           [   3,  515, 1028],\n",
      "           [   6,  515, 1028],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]]],\n",
      "\n",
      "\n",
      "         [[[   3,  515, 1027],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   3,  515, 1028],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[   3,  515, 1028],\n",
      "           [   6,  515, 1028],\n",
      "           [   6,  515, 1028],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   3,  515, 1028],\n",
      "           [   6,  515, 1028],\n",
      "           [   6,  515, 1028],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   3,  515, 1028],\n",
      "           [   6,  515, 1028],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]]],\n",
      "\n",
      "\n",
      "         [[[   3,  515, 1028],\n",
      "           [   3,  515, 1027],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   3,  515, 1028],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[   6,  515, 1028],\n",
      "           [   6,  515, 1028],\n",
      "           [   6,  515, 1028],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   6,  515, 1028],\n",
      "           [   6,  515, 1028],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   6,  515, 1028],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[   6,  515, 1028],\n",
      "           [   6,  515, 1028],\n",
      "           [   6,  515, 1028],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   6,  515, 1028],\n",
      "           [   6,  515, 1028],\n",
      "           [   6,  515, 1028],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   6,  515, 1028],\n",
      "           [   6,  515, 1028],\n",
      "           [   6,  515, 1028],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   6,  515, 1028],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   6,  515, 1028],\n",
      "           [   6,  515, 1028],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]]],\n",
      "\n",
      "\n",
      "         [[[   6,  515, 1028],\n",
      "           [   6,  515, 1028],\n",
      "           [   3,  515, 1028],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   6,  515, 1028],\n",
      "           [   6,  515, 1028],\n",
      "           [   3,  515, 1028],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   6,  515, 1028],\n",
      "           [   6,  515, 1028],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[   6,  515, 1028],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   6,  515, 1028],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]]],\n",
      "\n",
      "\n",
      "         [[[   6,  515, 1028],\n",
      "           [   3,  515, 1028],\n",
      "           [   3,  515, 1027],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   6,  515, 1028],\n",
      "           [   3,  515, 1028],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   6,  515, 1028],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[   6,  515, 1028],\n",
      "           [   6,  515, 1028],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   6,  515, 1028],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   3,  515, 1027],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   3,  515, 1027],\n",
      "           [   3,  515, 1027],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]]],\n",
      "\n",
      "\n",
      "         [[[   3,  515, 1027],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   3,  515, 1027],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]]],\n",
      "\n",
      "\n",
      "         [[[   3,  515, 1027],\n",
      "           [   3,  515, 1027],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   3,  515, 1027],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]]],\n",
      "\n",
      "\n",
      "         [[[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]]],\n",
      "\n",
      "\n",
      "         [[[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]]]]]), 'out_degree': tensor([[2, 3, 4, 3, 4, 3, 2, 4, 3, 4, 5, 2, 2, 3, 4, 4, 2, 3, 3, 4, 2, 4, 2, 3,\n",
      "         4, 3],\n",
      "        [2, 3, 3, 4, 3, 3, 4, 3, 3, 3, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]]), 'labels': tensor([-1., -1.]), 'spec': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'prec_mz': [418.0138, 164.0818], 'prec_mz_bin': [418, 164], 'prec_diff': [9.999999997489795e-05, 0.0004000000000132786], 'num_peaks': [30, 27], 'inst_type': ['FT', 'FT'], 'prec_type': ['[M+H]+', '[M+H]+'], 'frag_mode': ['HCD', 'HCD'], 'col_energy': [30.0, 60.0], 'charge': [1, 1], 'spec_meta': tensor([[-0.8749,  1.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          1.0000, -0.8749],\n",
      "        [-0.1061,  1.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          1.0000, -0.1061]]), 'mol_id': tensor([9861, 8990]), 'spec_id': tensor([11321, 11425]), 'group_id': tensor([0, 1]), 'prec_mz_idx': tensor([418, 164]), 'smiles': ['COc1cc(OC)n2nc(S(=O)(=O)Nc3c(Cl)ccc(C)c3Cl)nc2n1', 'COCn1nnc2ccccc21'], 'formula': ['C14H13Cl2N5O4S', 'C8H9N3O']}\n"
     ]
    }
   ],
   "source": [
    "collator = demo_dataset.get_collate_fn()\n",
    "# print(demo_dataset[5])\n",
    "# print(demo_dataset[6])\n",
    "collator_example = [demo_dataset[0], demo_dataset[1]]\n",
    "collator_result = collator(collator_example)\n",
    "print(collator_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_classes': 1, 'num_atoms': 4608, 'num_in_degree': 512, 'num_out_degree': 512, 'num_edges': 1536, 'num_spatial': 512, 'num_edge_dis': 128, 'edge_type': 'multi_hop', 'multi_hop_max_dist': 5, 'spatial_pos_max': 1024, 'max_nodes': 512, 'num_hidden_layers': 12, 'embedding_dim': 768, 'hidden_size': 768, 'ffn_embedding_dim': 768, 'num_attention_heads': 32, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'layerdrop': 0.0, 'encoder_normalize_before': False, 'pre_layernorm': False, 'apply_graphormer_init': False, 'activation_fn': 'gelu', 'embed_scale': None, 'freeze_embeddings': False, 'num_trans_layers_to_freeze': 0, 'share_input_output_embed': False, 'traceable': False, 'q_noise': 0.0, 'qn_block_size': 8, 'kdim': None, 'vdim': None, 'self_attention': True, 'bias': True, 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': None, 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'chunk_size_feed_forward': 0, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': None, 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': 1, 'pad_token_id': 0, 'eos_token_id': 2, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': '', '_commit_hash': None, 'transformers_version': None}\n"
     ]
    }
   ],
   "source": [
    "from transformers import GraphormerConfig, GraphormerModel\n",
    "graphormer_config = GraphormerConfig()\n",
    "print(graphormer_config.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'training': True, '_parameters': OrderedDict(), '_buffers': OrderedDict(), '_non_persistent_buffers_set': set(), '_backward_pre_hooks': OrderedDict(), '_backward_hooks': OrderedDict(), '_is_full_backward_hook': None, '_forward_hooks': OrderedDict(), '_forward_hooks_with_kwargs': OrderedDict(), '_forward_hooks_always_called': OrderedDict(), '_forward_pre_hooks': OrderedDict(), '_forward_pre_hooks_with_kwargs': OrderedDict(), '_state_dict_hooks': OrderedDict(), '_state_dict_pre_hooks': OrderedDict(), '_load_state_dict_pre_hooks': OrderedDict(), '_load_state_dict_post_hooks': OrderedDict(), '_modules': OrderedDict([('graph_encoder', GraphormerGraphEncoder(\n",
      "  (dropout_module): Dropout(p=0.1, inplace=False)\n",
      "  (graph_node_feature): GraphormerGraphNodeFeature(\n",
      "    (atom_encoder): Embedding(4609, 768, padding_idx=0)\n",
      "    (in_degree_encoder): Embedding(512, 768, padding_idx=0)\n",
      "    (out_degree_encoder): Embedding(512, 768, padding_idx=0)\n",
      "    (graph_token): Embedding(1, 768)\n",
      "  )\n",
      "  (graph_attn_bias): GraphormerGraphAttnBias(\n",
      "    (edge_encoder): Embedding(1537, 32, padding_idx=0)\n",
      "    (edge_dis_encoder): Embedding(131072, 1)\n",
      "    (spatial_pos_encoder): Embedding(512, 32, padding_idx=0)\n",
      "    (graph_token_virtual_distance): Embedding(1, 32)\n",
      "  )\n",
      "  (layers): ModuleList(\n",
      "    (0-11): 12 x GraphormerGraphEncoderLayer(\n",
      "      (dropout_module): Dropout(p=0.1, inplace=False)\n",
      "      (activation_dropout_module): Dropout(p=0.1, inplace=False)\n",
      "      (activation_fn): GELUActivation()\n",
      "      (self_attn): GraphormerMultiheadAttention(\n",
      "        (attention_dropout_module): Dropout(p=0.1, inplace=False)\n",
      "        (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (fc1): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (fc2): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      ")), ('lm_head_transform_weight', Linear(in_features=768, out_features=768, bias=True)), ('activation_fn', GELUActivation()), ('layer_norm', LayerNorm((768,), eps=1e-05, elementwise_affine=True))]), 'config': GraphormerConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_fn\": \"gelu\",\n",
      "  \"apply_graphormer_init\": false,\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bias\": true,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"dropout\": 0.1,\n",
      "  \"edge_type\": \"multi_hop\",\n",
      "  \"embed_scale\": null,\n",
      "  \"embedding_dim\": 768,\n",
      "  \"encoder_normalize_before\": false,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_embedding_dim\": 768,\n",
      "  \"freeze_embeddings\": false,\n",
      "  \"hidden_size\": 768,\n",
      "  \"kdim\": null,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"max_nodes\": 512,\n",
      "  \"model_type\": \"graphormer\",\n",
      "  \"multi_hop_max_dist\": 5,\n",
      "  \"num_atoms\": 4608,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_classes\": 1,\n",
      "  \"num_edge_dis\": 128,\n",
      "  \"num_edges\": 1536,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_in_degree\": 512,\n",
      "  \"num_out_degree\": 512,\n",
      "  \"num_spatial\": 512,\n",
      "  \"num_trans_layers_to_freeze\": 0,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pre_layernorm\": false,\n",
      "  \"q_noise\": 0.0,\n",
      "  \"qn_block_size\": 8,\n",
      "  \"self_attention\": true,\n",
      "  \"share_input_output_embed\": false,\n",
      "  \"spatial_pos_max\": 1024,\n",
      "  \"traceable\": false,\n",
      "  \"transformers_version\": \"4.35.2\",\n",
      "  \"vdim\": null\n",
      "}\n",
      ", 'name_or_path': '', 'warnings_issued': {}, 'generation_config': None, 'max_nodes': 512, 'share_input_output_embed': False, 'lm_output_learned_bias': None, 'load_softmax': True, '_is_hf_initialized': True}\n"
     ]
    }
   ],
   "source": [
    "model = GraphormerModel(config=graphormer_config)\n",
    "print(model.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MassFormer(nn.Module):\n",
    "\n",
    "    def __init__(self, graphormer_config, mlp_config):\n",
    "        super(MassFormer, self).__init__()\n",
    "        self.graphormer_module = GraphormerModel(config=graphormer_config)\n",
    "        # self.mlp_module = MLPModule(**mlp_config)\n",
    "\n",
    "\n",
    "    def get_graph_data(self, graph_entry):\n",
    "        print(f\"all keys = {list(graph_entry.keys())}\")\n",
    "\n",
    "        # this list of arguments is basically what preprocess_item produces\n",
    "        gf_keys = ['input_nodes', 'attn_bias', 'attn_edge_type', 'spatial_pos', 'in_degree', 'out_degree', 'input_edges', 'labels']\n",
    "        gf_item = {}\n",
    "        for k in gf_keys:\n",
    "            # note: some keys are optional, so we need to check for them\n",
    "            if k in graph_entry:\n",
    "                gf_item[k] = graph_entry[k]\n",
    "            else:\n",
    "                # helpful debugging message\n",
    "                print(f\"Warning: {k} not found in item\")\n",
    "        print(f\"gf_item = {list(gf_item.items())}\")    \n",
    "        return gf_item\n",
    "        \n",
    "\n",
    "    def get_spec_data(self, spec_entry):\n",
    "        print(f\"all keys = {list(spec_entry.keys())}\")\n",
    "        # remove gf-related keys\n",
    "        gf_related_keys = ['spatial_pos', 'labels', 'y', 'edge_index', 'edge_attr', 'num_nodes', 'attn_bias', 'input_nodes', 'attn_edge_type', 'in_degree', 'input_edges', 'out_degree', 'x']\n",
    "        for k in gf_related_keys:\n",
    "                # note: some keys are optional, so we need to check for them\n",
    "                if k in spec_entry:\n",
    "                    spec_entry.pop(k)\n",
    "                else:\n",
    "                    print(f\"Warning: {k} not found in item\")\n",
    "\n",
    "        # now, let's handle the rest of the stuff\n",
    "        spec_item = {k: [] for k in spec_entry.keys()}\n",
    "        for k, v in spec_entry.items():\n",
    "                    spec_item[k] = (v)\n",
    "        # for k, v in other_collated.items():\n",
    "        #     if isinstance(items[0][k], th.Tensor):\n",
    "        #         other_collated[k] = th.cat(v, dim=0)\n",
    "        #     elif isinstance(items[0][k], list):\n",
    "        #         other_collated[k] = utils.flatten_lol(v)\n",
    "        #     else:\n",
    "        #         raise ValueError(f\"{type(items[0][k])} is not supported\")\n",
    "\n",
    "        print(f\"spec_item = {list(spec_item.items())}\")\n",
    "        return spec_item\n",
    "        \n",
    "\n",
    "    # def forward(self, data):\n",
    "\n",
    "    #     graph_data = self.get_graph_data(data)\n",
    "    #     spec_data = self.get_spec_data(data)\n",
    "    #     graph_embedding = self.graphormer_module(graph_data)\n",
    "    #     output = self.mlp_module(graph_embedding,spec_data)\n",
    "    #     return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'training': True, '_parameters': OrderedDict(), '_buffers': OrderedDict(), '_non_persistent_buffers_set': set(), '_backward_pre_hooks': OrderedDict(), '_backward_hooks': OrderedDict(), '_is_full_backward_hook': None, '_forward_hooks': OrderedDict(), '_forward_hooks_with_kwargs': OrderedDict(), '_forward_hooks_always_called': OrderedDict(), '_forward_pre_hooks': OrderedDict(), '_forward_pre_hooks_with_kwargs': OrderedDict(), '_state_dict_hooks': OrderedDict(), '_state_dict_pre_hooks': OrderedDict(), '_load_state_dict_pre_hooks': OrderedDict(), '_load_state_dict_post_hooks': OrderedDict(), '_modules': OrderedDict([('graphormer_module', GraphormerModel(\n",
      "  (graph_encoder): GraphormerGraphEncoder(\n",
      "    (dropout_module): Dropout(p=0.1, inplace=False)\n",
      "    (graph_node_feature): GraphormerGraphNodeFeature(\n",
      "      (atom_encoder): Embedding(4609, 768, padding_idx=0)\n",
      "      (in_degree_encoder): Embedding(512, 768, padding_idx=0)\n",
      "      (out_degree_encoder): Embedding(512, 768, padding_idx=0)\n",
      "      (graph_token): Embedding(1, 768)\n",
      "    )\n",
      "    (graph_attn_bias): GraphormerGraphAttnBias(\n",
      "      (edge_encoder): Embedding(1537, 32, padding_idx=0)\n",
      "      (edge_dis_encoder): Embedding(131072, 1)\n",
      "      (spatial_pos_encoder): Embedding(512, 32, padding_idx=0)\n",
      "      (graph_token_virtual_distance): Embedding(1, 32)\n",
      "    )\n",
      "    (layers): ModuleList(\n",
      "      (0-11): 12 x GraphormerGraphEncoderLayer(\n",
      "        (dropout_module): Dropout(p=0.1, inplace=False)\n",
      "        (activation_dropout_module): Dropout(p=0.1, inplace=False)\n",
      "        (activation_fn): GELUActivation()\n",
      "        (self_attn): GraphormerMultiheadAttention(\n",
      "          (attention_dropout_module): Dropout(p=0.1, inplace=False)\n",
      "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (fc2): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (lm_head_transform_weight): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (activation_fn): GELUActivation()\n",
      "  (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "))])}\n"
     ]
    }
   ],
   "source": [
    "massformer_example = MassFormer(graphormer_config, graphormer_config)\n",
    "print(massformer_example.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all keys = ['attn_bias', 'attn_edge_type', 'spatial_pos', 'in_degree', 'input_nodes', 'input_edges', 'out_degree', 'labels', 'spec', 'prec_mz', 'prec_mz_bin', 'prec_diff', 'num_peaks', 'inst_type', 'prec_type', 'frag_mode', 'col_energy', 'charge', 'spec_meta', 'mol_id', 'spec_id', 'group_id', 'prec_mz_idx', 'smiles', 'formula']\n",
      "gf_item = [('input_nodes', tensor([[[4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4]],\n",
      "\n",
      "        [[4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [0],\n",
      "         [0],\n",
      "         [0],\n",
      "         [0],\n",
      "         [0],\n",
      "         [0],\n",
      "         [0],\n",
      "         [0],\n",
      "         [0],\n",
      "         [0],\n",
      "         [0],\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]]])), ('attn_bias', tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])), ('attn_edge_type', tensor([[[[   0,    0,    0],\n",
      "          [   2,  514, 1026],\n",
      "          [   0,    0,    0],\n",
      "          ...,\n",
      "          [   0,    0,    0],\n",
      "          [   0,    0,    0],\n",
      "          [   0,    0,    0]],\n",
      "\n",
      "         [[   2,  514, 1026],\n",
      "          [   0,    0,    0],\n",
      "          [   2,  514, 1027],\n",
      "          ...,\n",
      "          [   0,    0,    0],\n",
      "          [   0,    0,    0],\n",
      "          [   0,    0,    0]],\n",
      "\n",
      "         [[   0,    0,    0],\n",
      "          [   2,  514, 1027],\n",
      "          [   0,    0,    0],\n",
      "          ...,\n",
      "          [   0,    0,    0],\n",
      "          [   0,    0,    0],\n",
      "          [   5,  514, 1027]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[   0,    0,    0],\n",
      "          [   0,    0,    0],\n",
      "          [   0,    0,    0],\n",
      "          ...,\n",
      "          [   0,    0,    0],\n",
      "          [   5,  514, 1027],\n",
      "          [   0,    0,    0]],\n",
      "\n",
      "         [[   0,    0,    0],\n",
      "          [   0,    0,    0],\n",
      "          [   0,    0,    0],\n",
      "          ...,\n",
      "          [   5,  514, 1027],\n",
      "          [   0,    0,    0],\n",
      "          [   5,  514, 1027]],\n",
      "\n",
      "         [[   0,    0,    0],\n",
      "          [   0,    0,    0],\n",
      "          [   5,  514, 1027],\n",
      "          ...,\n",
      "          [   0,    0,    0],\n",
      "          [   5,  514, 1027],\n",
      "          [   0,    0,    0]]],\n",
      "\n",
      "\n",
      "        [[[   0,    0,    0],\n",
      "          [   2,  514, 1026],\n",
      "          [   0,    0,    0],\n",
      "          ...,\n",
      "          [   0,    0,    0],\n",
      "          [   0,    0,    0],\n",
      "          [   0,    0,    0]],\n",
      "\n",
      "         [[   2,  514, 1026],\n",
      "          [   0,    0,    0],\n",
      "          [   2,  514, 1026],\n",
      "          ...,\n",
      "          [   0,    0,    0],\n",
      "          [   0,    0,    0],\n",
      "          [   0,    0,    0]],\n",
      "\n",
      "         [[   0,    0,    0],\n",
      "          [   2,  514, 1026],\n",
      "          [   0,    0,    0],\n",
      "          ...,\n",
      "          [   0,    0,    0],\n",
      "          [   0,    0,    0],\n",
      "          [   0,    0,    0]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[   0,    0,    0],\n",
      "          [   0,    0,    0],\n",
      "          [   0,    0,    0],\n",
      "          ...,\n",
      "          [   0,    0,    0],\n",
      "          [   0,    0,    0],\n",
      "          [   0,    0,    0]],\n",
      "\n",
      "         [[   0,    0,    0],\n",
      "          [   0,    0,    0],\n",
      "          [   0,    0,    0],\n",
      "          ...,\n",
      "          [   0,    0,    0],\n",
      "          [   0,    0,    0],\n",
      "          [   0,    0,    0]],\n",
      "\n",
      "         [[   0,    0,    0],\n",
      "          [   0,    0,    0],\n",
      "          [   0,    0,    0],\n",
      "          ...,\n",
      "          [   0,    0,    0],\n",
      "          [   0,    0,    0],\n",
      "          [   0,    0,    0]]]])), ('spatial_pos', tensor([[[1, 2, 3,  ..., 6, 5, 4],\n",
      "         [2, 1, 2,  ..., 5, 4, 3],\n",
      "         [3, 2, 1,  ..., 4, 3, 2],\n",
      "         ...,\n",
      "         [6, 5, 4,  ..., 1, 2, 3],\n",
      "         [5, 4, 3,  ..., 2, 1, 2],\n",
      "         [4, 3, 2,  ..., 3, 2, 1]],\n",
      "\n",
      "        [[1, 2, 3,  ..., 0, 0, 0],\n",
      "         [2, 1, 2,  ..., 0, 0, 0],\n",
      "         [3, 2, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]]])), ('in_degree', tensor([[2, 3, 4, 3, 4, 3, 2, 4, 3, 4, 5, 2, 2, 3, 4, 4, 2, 3, 3, 4, 2, 4, 2, 3,\n",
      "         4, 3],\n",
      "        [2, 3, 3, 4, 3, 3, 4, 3, 3, 3, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]])), ('out_degree', tensor([[2, 3, 4, 3, 4, 3, 2, 4, 3, 4, 5, 2, 2, 3, 4, 4, 2, 3, 3, 4, 2, 4, 2, 3,\n",
      "         4, 3],\n",
      "        [2, 3, 3, 4, 3, 3, 4, 3, 3, 3, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]])), ('input_edges', tensor([[[[[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   3,  515, 1027],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   3,  515, 1027],\n",
      "           [   3,  515, 1028],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[   3,  515, 1027],\n",
      "           [   3,  515, 1028],\n",
      "           [   6,  515, 1028],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   3,  515, 1027],\n",
      "           [   3,  515, 1028],\n",
      "           [   6,  515, 1028],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   3,  515, 1027],\n",
      "           [   3,  515, 1028],\n",
      "           [   6,  515, 1028],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]]],\n",
      "\n",
      "\n",
      "         [[[   3,  515, 1027],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   3,  515, 1028],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[   3,  515, 1028],\n",
      "           [   6,  515, 1028],\n",
      "           [   6,  515, 1028],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   3,  515, 1028],\n",
      "           [   6,  515, 1028],\n",
      "           [   6,  515, 1028],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   3,  515, 1028],\n",
      "           [   6,  515, 1028],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]]],\n",
      "\n",
      "\n",
      "         [[[   3,  515, 1028],\n",
      "           [   3,  515, 1027],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   3,  515, 1028],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[   6,  515, 1028],\n",
      "           [   6,  515, 1028],\n",
      "           [   6,  515, 1028],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   6,  515, 1028],\n",
      "           [   6,  515, 1028],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   6,  515, 1028],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[   6,  515, 1028],\n",
      "           [   6,  515, 1028],\n",
      "           [   6,  515, 1028],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   6,  515, 1028],\n",
      "           [   6,  515, 1028],\n",
      "           [   6,  515, 1028],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   6,  515, 1028],\n",
      "           [   6,  515, 1028],\n",
      "           [   6,  515, 1028],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   6,  515, 1028],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   6,  515, 1028],\n",
      "           [   6,  515, 1028],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]]],\n",
      "\n",
      "\n",
      "         [[[   6,  515, 1028],\n",
      "           [   6,  515, 1028],\n",
      "           [   3,  515, 1028],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   6,  515, 1028],\n",
      "           [   6,  515, 1028],\n",
      "           [   3,  515, 1028],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   6,  515, 1028],\n",
      "           [   6,  515, 1028],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[   6,  515, 1028],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   6,  515, 1028],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]]],\n",
      "\n",
      "\n",
      "         [[[   6,  515, 1028],\n",
      "           [   3,  515, 1028],\n",
      "           [   3,  515, 1027],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   6,  515, 1028],\n",
      "           [   3,  515, 1028],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   6,  515, 1028],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[   6,  515, 1028],\n",
      "           [   6,  515, 1028],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   6,  515, 1028],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   3,  515, 1027],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   3,  515, 1027],\n",
      "           [   3,  515, 1027],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]]],\n",
      "\n",
      "\n",
      "         [[[   3,  515, 1027],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   3,  515, 1027],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]]],\n",
      "\n",
      "\n",
      "         [[[   3,  515, 1027],\n",
      "           [   3,  515, 1027],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   3,  515, 1027],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]]],\n",
      "\n",
      "\n",
      "         [[[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]]],\n",
      "\n",
      "\n",
      "         [[[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]],\n",
      "\n",
      "          [[   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           ...,\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0],\n",
      "           [   0,    0,    0]]]]])), ('labels', tensor([-1., -1.]))]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_nodes': tensor([[[4],\n",
       "          [4],\n",
       "          [4],\n",
       "          [4],\n",
       "          [4],\n",
       "          [4],\n",
       "          [4],\n",
       "          [4],\n",
       "          [4],\n",
       "          [4],\n",
       "          [4],\n",
       "          [4],\n",
       "          [4],\n",
       "          [4],\n",
       "          [4],\n",
       "          [4],\n",
       "          [4],\n",
       "          [4],\n",
       "          [4],\n",
       "          [4],\n",
       "          [4],\n",
       "          [4],\n",
       "          [4],\n",
       "          [4],\n",
       "          [4],\n",
       "          [4]],\n",
       " \n",
       "         [[4],\n",
       "          [4],\n",
       "          [4],\n",
       "          [4],\n",
       "          [4],\n",
       "          [4],\n",
       "          [4],\n",
       "          [4],\n",
       "          [4],\n",
       "          [4],\n",
       "          [4],\n",
       "          [4],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]]]),\n",
       " 'attn_bias': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]),\n",
       " 'attn_edge_type': tensor([[[[   0,    0,    0],\n",
       "           [   2,  514, 1026],\n",
       "           [   0,    0,    0],\n",
       "           ...,\n",
       "           [   0,    0,    0],\n",
       "           [   0,    0,    0],\n",
       "           [   0,    0,    0]],\n",
       " \n",
       "          [[   2,  514, 1026],\n",
       "           [   0,    0,    0],\n",
       "           [   2,  514, 1027],\n",
       "           ...,\n",
       "           [   0,    0,    0],\n",
       "           [   0,    0,    0],\n",
       "           [   0,    0,    0]],\n",
       " \n",
       "          [[   0,    0,    0],\n",
       "           [   2,  514, 1027],\n",
       "           [   0,    0,    0],\n",
       "           ...,\n",
       "           [   0,    0,    0],\n",
       "           [   0,    0,    0],\n",
       "           [   5,  514, 1027]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[   0,    0,    0],\n",
       "           [   0,    0,    0],\n",
       "           [   0,    0,    0],\n",
       "           ...,\n",
       "           [   0,    0,    0],\n",
       "           [   5,  514, 1027],\n",
       "           [   0,    0,    0]],\n",
       " \n",
       "          [[   0,    0,    0],\n",
       "           [   0,    0,    0],\n",
       "           [   0,    0,    0],\n",
       "           ...,\n",
       "           [   5,  514, 1027],\n",
       "           [   0,    0,    0],\n",
       "           [   5,  514, 1027]],\n",
       " \n",
       "          [[   0,    0,    0],\n",
       "           [   0,    0,    0],\n",
       "           [   5,  514, 1027],\n",
       "           ...,\n",
       "           [   0,    0,    0],\n",
       "           [   5,  514, 1027],\n",
       "           [   0,    0,    0]]],\n",
       " \n",
       " \n",
       "         [[[   0,    0,    0],\n",
       "           [   2,  514, 1026],\n",
       "           [   0,    0,    0],\n",
       "           ...,\n",
       "           [   0,    0,    0],\n",
       "           [   0,    0,    0],\n",
       "           [   0,    0,    0]],\n",
       " \n",
       "          [[   2,  514, 1026],\n",
       "           [   0,    0,    0],\n",
       "           [   2,  514, 1026],\n",
       "           ...,\n",
       "           [   0,    0,    0],\n",
       "           [   0,    0,    0],\n",
       "           [   0,    0,    0]],\n",
       " \n",
       "          [[   0,    0,    0],\n",
       "           [   2,  514, 1026],\n",
       "           [   0,    0,    0],\n",
       "           ...,\n",
       "           [   0,    0,    0],\n",
       "           [   0,    0,    0],\n",
       "           [   0,    0,    0]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[   0,    0,    0],\n",
       "           [   0,    0,    0],\n",
       "           [   0,    0,    0],\n",
       "           ...,\n",
       "           [   0,    0,    0],\n",
       "           [   0,    0,    0],\n",
       "           [   0,    0,    0]],\n",
       " \n",
       "          [[   0,    0,    0],\n",
       "           [   0,    0,    0],\n",
       "           [   0,    0,    0],\n",
       "           ...,\n",
       "           [   0,    0,    0],\n",
       "           [   0,    0,    0],\n",
       "           [   0,    0,    0]],\n",
       " \n",
       "          [[   0,    0,    0],\n",
       "           [   0,    0,    0],\n",
       "           [   0,    0,    0],\n",
       "           ...,\n",
       "           [   0,    0,    0],\n",
       "           [   0,    0,    0],\n",
       "           [   0,    0,    0]]]]),\n",
       " 'spatial_pos': tensor([[[1, 2, 3,  ..., 6, 5, 4],\n",
       "          [2, 1, 2,  ..., 5, 4, 3],\n",
       "          [3, 2, 1,  ..., 4, 3, 2],\n",
       "          ...,\n",
       "          [6, 5, 4,  ..., 1, 2, 3],\n",
       "          [5, 4, 3,  ..., 2, 1, 2],\n",
       "          [4, 3, 2,  ..., 3, 2, 1]],\n",
       " \n",
       "         [[1, 2, 3,  ..., 0, 0, 0],\n",
       "          [2, 1, 2,  ..., 0, 0, 0],\n",
       "          [3, 2, 1,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]]]),\n",
       " 'in_degree': tensor([[2, 3, 4, 3, 4, 3, 2, 4, 3, 4, 5, 2, 2, 3, 4, 4, 2, 3, 3, 4, 2, 4, 2, 3,\n",
       "          4, 3],\n",
       "         [2, 3, 3, 4, 3, 3, 4, 3, 3, 3, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0]]),\n",
       " 'out_degree': tensor([[2, 3, 4, 3, 4, 3, 2, 4, 3, 4, 5, 2, 2, 3, 4, 4, 2, 3, 3, 4, 2, 4, 2, 3,\n",
       "          4, 3],\n",
       "         [2, 3, 3, 4, 3, 3, 4, 3, 3, 3, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0]]),\n",
       " 'input_edges': tensor([[[[[   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           [[   3,  515, 1027],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           [[   3,  515, 1027],\n",
       "            [   3,  515, 1028],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           ...,\n",
       " \n",
       "           [[   3,  515, 1027],\n",
       "            [   3,  515, 1028],\n",
       "            [   6,  515, 1028],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           [[   3,  515, 1027],\n",
       "            [   3,  515, 1028],\n",
       "            [   6,  515, 1028],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           [[   3,  515, 1027],\n",
       "            [   3,  515, 1028],\n",
       "            [   6,  515, 1028],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]]],\n",
       " \n",
       " \n",
       "          [[[   3,  515, 1027],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           [[   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           [[   3,  515, 1028],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           ...,\n",
       " \n",
       "           [[   3,  515, 1028],\n",
       "            [   6,  515, 1028],\n",
       "            [   6,  515, 1028],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           [[   3,  515, 1028],\n",
       "            [   6,  515, 1028],\n",
       "            [   6,  515, 1028],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           [[   3,  515, 1028],\n",
       "            [   6,  515, 1028],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]]],\n",
       " \n",
       " \n",
       "          [[[   3,  515, 1028],\n",
       "            [   3,  515, 1027],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           [[   3,  515, 1028],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           [[   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           ...,\n",
       " \n",
       "           [[   6,  515, 1028],\n",
       "            [   6,  515, 1028],\n",
       "            [   6,  515, 1028],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           [[   6,  515, 1028],\n",
       "            [   6,  515, 1028],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           [[   6,  515, 1028],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]]],\n",
       " \n",
       " \n",
       "          ...,\n",
       " \n",
       " \n",
       "          [[[   6,  515, 1028],\n",
       "            [   6,  515, 1028],\n",
       "            [   6,  515, 1028],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           [[   6,  515, 1028],\n",
       "            [   6,  515, 1028],\n",
       "            [   6,  515, 1028],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           [[   6,  515, 1028],\n",
       "            [   6,  515, 1028],\n",
       "            [   6,  515, 1028],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           ...,\n",
       " \n",
       "           [[   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           [[   6,  515, 1028],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           [[   6,  515, 1028],\n",
       "            [   6,  515, 1028],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]]],\n",
       " \n",
       " \n",
       "          [[[   6,  515, 1028],\n",
       "            [   6,  515, 1028],\n",
       "            [   3,  515, 1028],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           [[   6,  515, 1028],\n",
       "            [   6,  515, 1028],\n",
       "            [   3,  515, 1028],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           [[   6,  515, 1028],\n",
       "            [   6,  515, 1028],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           ...,\n",
       " \n",
       "           [[   6,  515, 1028],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           [[   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           [[   6,  515, 1028],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]]],\n",
       " \n",
       " \n",
       "          [[[   6,  515, 1028],\n",
       "            [   3,  515, 1028],\n",
       "            [   3,  515, 1027],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           [[   6,  515, 1028],\n",
       "            [   3,  515, 1028],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           [[   6,  515, 1028],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           ...,\n",
       " \n",
       "           [[   6,  515, 1028],\n",
       "            [   6,  515, 1028],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           [[   6,  515, 1028],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           [[   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]]]],\n",
       " \n",
       " \n",
       " \n",
       "         [[[[   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           [[   3,  515, 1027],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           [[   3,  515, 1027],\n",
       "            [   3,  515, 1027],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           ...,\n",
       " \n",
       "           [[   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           [[   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           [[   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]]],\n",
       " \n",
       " \n",
       "          [[[   3,  515, 1027],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           [[   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           [[   3,  515, 1027],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           ...,\n",
       " \n",
       "           [[   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           [[   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           [[   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]]],\n",
       " \n",
       " \n",
       "          [[[   3,  515, 1027],\n",
       "            [   3,  515, 1027],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           [[   3,  515, 1027],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           [[   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           ...,\n",
       " \n",
       "           [[   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           [[   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           [[   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]]],\n",
       " \n",
       " \n",
       "          ...,\n",
       " \n",
       " \n",
       "          [[[   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           [[   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           [[   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           ...,\n",
       " \n",
       "           [[   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           [[   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           [[   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]]],\n",
       " \n",
       " \n",
       "          [[[   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           [[   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           [[   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           ...,\n",
       " \n",
       "           [[   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           [[   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           [[   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]]],\n",
       " \n",
       " \n",
       "          [[[   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           [[   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           [[   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           ...,\n",
       " \n",
       "           [[   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           [[   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]],\n",
       " \n",
       "           [[   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            ...,\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0],\n",
       "            [   0,    0,    0]]]]]),\n",
       " 'labels': tensor([-1., -1.])}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "massformer_example.get_graph_data(collator_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all keys = ['spec', 'prec_mz', 'prec_mz_bin', 'prec_diff', 'num_peaks', 'inst_type', 'prec_type', 'frag_mode', 'col_energy', 'charge', 'spec_meta', 'mol_id', 'spec_id', 'group_id', 'prec_mz_idx', 'smiles', 'formula']\n",
      "Warning: spatial_pos not found in item\n",
      "Warning: labels not found in item\n",
      "Warning: y not found in item\n",
      "Warning: edge_index not found in item\n",
      "Warning: edge_attr not found in item\n",
      "Warning: num_nodes not found in item\n",
      "Warning: attn_bias not found in item\n",
      "Warning: input_nodes not found in item\n",
      "Warning: attn_edge_type not found in item\n",
      "Warning: in_degree not found in item\n",
      "Warning: input_edges not found in item\n",
      "Warning: out_degree not found in item\n",
      "Warning: x not found in item\n",
      "spec_item = [('spec', tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])), ('prec_mz', [418.0138, 164.0818]), ('prec_mz_bin', [418, 164]), ('prec_diff', [9.999999997489795e-05, 0.0004000000000132786]), ('num_peaks', [30, 27]), ('inst_type', ['FT', 'FT']), ('prec_type', ['[M+H]+', '[M+H]+']), ('frag_mode', ['HCD', 'HCD']), ('col_energy', [30.0, 60.0]), ('charge', [1, 1]), ('spec_meta', tensor([[-0.8749,  1.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          1.0000, -0.8749],\n",
      "        [-0.1061,  1.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          1.0000, -0.1061]])), ('mol_id', tensor([9861, 8990])), ('spec_id', tensor([11321, 11425])), ('group_id', tensor([0, 1])), ('prec_mz_idx', tensor([418, 164])), ('smiles', ['COc1cc(OC)n2nc(S(=O)(=O)Nc3c(Cl)ccc(C)c3Cl)nc2n1', 'COCn1nnc2ccccc21']), ('formula', ['C14H13Cl2N5O4S', 'C8H9N3O'])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'spec': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " 'prec_mz': [418.0138, 164.0818],\n",
       " 'prec_mz_bin': [418, 164],\n",
       " 'prec_diff': [9.999999997489795e-05, 0.0004000000000132786],\n",
       " 'num_peaks': [30, 27],\n",
       " 'inst_type': ['FT', 'FT'],\n",
       " 'prec_type': ['[M+H]+', '[M+H]+'],\n",
       " 'frag_mode': ['HCD', 'HCD'],\n",
       " 'col_energy': [30.0, 60.0],\n",
       " 'charge': [1, 1],\n",
       " 'spec_meta': tensor([[-0.8749,  1.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           1.0000, -0.8749],\n",
       "         [-0.1061,  1.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           1.0000, -0.1061]]),\n",
       " 'mol_id': tensor([9861, 8990]),\n",
       " 'spec_id': tensor([11321, 11425]),\n",
       " 'group_id': tensor([0, 1]),\n",
       " 'prec_mz_idx': tensor([418, 164]),\n",
       " 'smiles': ['COc1cc(OC)n2nc(S(=O)(=O)Nc3c(Cl)ccc(C)c3Cl)nc2n1',\n",
       "  'COCn1nnc2ccccc21'],\n",
       " 'formula': ['C14H13Cl2N5O4S', 'C8H9N3O']}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "massformer_example.get_spec_data(collator_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_feats, out_feats, dropout=0.1):\n",
    "        super(LinearBlock, self).__init__()\n",
    "        self.linear = nn.Linear(in_feats, out_feats)\n",
    "        self.bn = nn.BatchNorm1d(out_feats)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.bn(self.dropout(F.relu(self.linear(x))))\n",
    "\n",
    "\n",
    "class NeimsBlock(nn.Module):\n",
    "    \"\"\" from the NEIMS paper (uses LeakyReLU instead of ReLU) \"\"\"\n",
    "\n",
    "    def __init__(self, in_dim, out_dim, dropout):\n",
    "\n",
    "        super(NeimsBlock, self).__init__()\n",
    "        bottleneck_factor = 0.5\n",
    "        bottleneck_size = int(round(bottleneck_factor * out_dim))\n",
    "        self.in_batch_norm = nn.BatchNorm1d(in_dim)\n",
    "        self.in_activation = nn.LeakyReLU()\n",
    "        self.in_linear = nn.Linear(in_dim, bottleneck_size)\n",
    "        self.out_batch_norm = nn.BatchNorm1d(bottleneck_size)\n",
    "        self.out_linear = nn.Linear(bottleneck_size, out_dim)\n",
    "        self.out_activation = nn.LeakyReLU()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        h = x\n",
    "        h = self.in_batch_norm(h)\n",
    "        h = self.in_activation(h)\n",
    "        h = self.dropout(h)\n",
    "        h = self.in_linear(h)\n",
    "        h = self.out_batch_norm(h)\n",
    "        h = self.out_activation(h)\n",
    "        h = self.out_linear(h)\n",
    "        return h\n",
    "\n",
    "def mask_prediction_by_mass(raw_prediction, prec_mass_idx, prec_mass_offset, mask_value=0.):\n",
    "    # adapted from NEIMS\n",
    "    # raw_prediction is [B,D], prec_mass_idx is [B]\n",
    "\n",
    "    max_idx = raw_prediction.shape[1]\n",
    "    assert th.all(prec_mass_idx < max_idx)\n",
    "    idx = th.arange(max_idx, device=prec_mass_idx.device)\n",
    "    mask = (\n",
    "        idx.unsqueeze(0) <= (\n",
    "            prec_mass_idx.unsqueeze(1) +\n",
    "            prec_mass_offset)).float()\n",
    "    return mask * raw_prediction + (1. - mask) * mask_value\n",
    "\n",
    "\n",
    "def reverse_prediction(raw_prediction, prec_mass_idx, prec_mass_offset):\n",
    "    # adapted from NEIMS\n",
    "    # raw_prediction is [B,D], prec_mass_idx is [B]\n",
    "\n",
    "    batch_size = raw_prediction.shape[0]\n",
    "    max_idx = raw_prediction.shape[1]\n",
    "    assert th.all(prec_mass_idx < max_idx)\n",
    "    rev_prediction = th.flip(raw_prediction, dims=(1,))\n",
    "    # convention is to shift right, so we express as negative to go left\n",
    "    offset_idx = th.minimum(\n",
    "        max_idx * th.ones_like(prec_mass_idx),\n",
    "        prec_mass_idx + prec_mass_offset + 1)\n",
    "    shifts = - (max_idx - offset_idx)\n",
    "    gather_idx = th.arange(\n",
    "        max_idx,\n",
    "        device=raw_prediction.device).unsqueeze(0).expand(\n",
    "        batch_size,\n",
    "        max_idx)\n",
    "    gather_idx = (gather_idx - shifts.unsqueeze(1)) % max_idx\n",
    "    offset_rev_prediction = th.gather(rev_prediction, 1, gather_idx)\n",
    "    # you could mask_prediction_by_mass here but it's unnecessary\n",
    "    return offset_rev_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: asssume we have graphormer model already\n",
    "class MLPModule(nn.Module):\n",
    "\n",
    "    def __init__(self, dim_d, **kwargs, config):\n",
    "\n",
    "        super(MLPModule, self).__init__()\n",
    "        self.g_dim = dim_d[\"g_dim\"]\n",
    "        self.o_dim = dim_d[\"o_dim\"]\n",
    "        for k, v in kwargs.items():\n",
    "            setattr(self, k, v)\n",
    "        # self.embedders = nn.ModuleList([])\n",
    "        # if \"fp\" in self.embed_types:\n",
    "        #     self.embedders.append(FPEmbedder(dim_d, **kwargs))\n",
    "        # if \"wln\" in self.embed_types:\n",
    "        #     self.embedders.append(WLNEmbedder(dim_d, **kwargs))\n",
    "\n",
    "        # if \"gf_v2\" in self.embed_types:\n",
    "        #     self.embedders.append(GFv2Embedder(**kwargs))\n",
    "        # assert len(self.embedders) > 0, len(self.embedders)\n",
    "        # embeds_dims = [embedder.get_embed_dim() for embedder in self.embedders]\n",
    "        # TODO: Changed here for embedder\n",
    "        embeds_dims = self.embedder.embedding_dim\n",
    "        if self.g_dim > 0:\n",
    "            embeds_dims.append(self.g_dim)\n",
    "        if self.embed_dim == -1:\n",
    "            # infer embed_dim\n",
    "            self.embed_dim = sum(embeds_dims)\n",
    "        # TODO: MLP \n",
    "        if self.embed_linear:\n",
    "            self.embed_layers = nn.ModuleList(\n",
    "                [nn.Linear(embed_dim, self.embed_dim) for embed_dim in embeds_dims])\n",
    "        else:\n",
    "            self.embed_layers = nn.ModuleList(\n",
    "                [nn.Identity() for embed_dim in embeds_dims])\n",
    "        self.ff_layers = nn.ModuleList([])\n",
    "        self.out_modules = []\n",
    "        if self.ff_layer_type == \"standard\":\n",
    "            ff_layer = LinearBlock\n",
    "        else:\n",
    "            assert self.ff_layer_type == \"neims\", self.ff_layer_type\n",
    "            ff_layer = NeimsBlock\n",
    "        self.ff_layers.append(nn.Linear(self.embed_dim, self.ff_h_dim))\n",
    "        self.out_modules.extend([\"ff_layers\"])\n",
    "        for i in range(self.ff_num_layers):\n",
    "            self.ff_layers.append(\n",
    "                ff_layer(\n",
    "                    self.ff_h_dim,\n",
    "                    self.ff_h_dim,\n",
    "                    self.dropout))\n",
    "        if self.bidirectional_prediction:\n",
    "            # assumes gating, mass masking\n",
    "            self.forw_out_layer = nn.Linear(self.ff_h_dim, self.o_dim)\n",
    "            self.rev_out_layer = nn.Linear(self.ff_h_dim, self.o_dim)\n",
    "            self.out_gate = nn.Sequential(\n",
    "                *[nn.Linear(self.ff_h_dim, self.o_dim), nn.Sigmoid()])\n",
    "            self.out_modules.extend(\n",
    "                [\"forw_out_layer\", \"rev_out_layer\", \"out_gate\"])\n",
    "        else:\n",
    "            self.out_layer = nn.Linear(self.ff_h_dim, self.o_dim)\n",
    "            if self.gate_prediction:\n",
    "                self.out_gate = nn.Sequential(\n",
    "                    *[nn.Linear(self.ff_h_dim, self.o_dim), nn.Sigmoid()])\n",
    "            self.out_modules.extend([\"out_layer\", \"out_gate\"])\n",
    "        # if self.spectrum_attention:\n",
    "        #     self.spectrum_attender = SpectrumAttention(self.o_dim, 100, 10)\n",
    "        #     self.out_modules.extend([\"spectrum_attender\"])\n",
    "\n",
    "    # TODO: \n",
    "    def forward(self, data, perturb=None, amp=False, return_input_feats=\"\", return_lda_pred=False):\n",
    "        if return_input_feats:\n",
    "            assert len(self.embedders) == 1\n",
    "            embedder = self.embedders[0]\n",
    "            # assert isinstance(embedder, GFv2Embedder)\n",
    "            embed, input_feats = embedder(\n",
    "                data,\n",
    "                perturb=perturb,\n",
    "                return_input_feats=return_input_feats\n",
    "            )\n",
    "            embeds = [embed]\n",
    "        else:\n",
    "            embeds = [embedder(data, perturb=perturb)\n",
    "                    for embedder in self.embedders]\n",
    "        # add on metadata\n",
    "        if self.g_dim > 0:\n",
    "            embeds.append(data[\"spec_meta\"])\n",
    "            # apply transformation\n",
    "            embeds = [\n",
    "                self.embed_layers[embed_idx](embed) for embed_idx,\n",
    "                embed in enumerate(embeds)]\n",
    "        # aggregate\n",
    "        if self.embed_agg == \"concat\":\n",
    "            fh = th.cat(embeds, dim=1)\n",
    "        elif self.embed_agg == \"add\":\n",
    "            assert all(embed.shape[1] == embeds[0].shape[1]\n",
    "                   for embed in embeds)\n",
    "            fh = sum(embeds)\n",
    "        elif self.embed_agg == \"avg\":\n",
    "            fh = sum(embeds) / len(embeds)\n",
    "        else:\n",
    "            raise ValueError(\"invalid agg_embed\")\n",
    "        # apply feedforward layers\n",
    "        fh = self.ff_layers[0](fh)\n",
    "        for ff_layer in self.ff_layers[1:]:\n",
    "            if self.ff_skip:\n",
    "                fh = fh + ff_layer(fh)\n",
    "            else:\n",
    "                fh = ff_layer(fh)\n",
    "        if self.bidirectional_prediction:\n",
    "            ff = self.forw_out_layer(fh)\n",
    "            fr = reverse_prediction(\n",
    "                self.rev_out_layer(fh),\n",
    "                data[\"prec_mz_idx\"],\n",
    "                self.prec_mass_offset)\n",
    "            fg = self.out_gate(fh)\n",
    "            fo = ff * fg + fr * (1. - fg)\n",
    "            fo = mask_prediction_by_mass(\n",
    "                fo, data[\"prec_mz_idx\"], self.prec_mass_offset)\n",
    "        else:\n",
    "            # apply output layer\n",
    "            fo = self.out_layer(fh)\n",
    "            # apply gating\n",
    "            if self.gate_prediction:\n",
    "                    fg = self.out_gate(fh)\n",
    "                    fo = fg * fo\n",
    "            # apply output activation\n",
    "            if self.output_activation == \"relu\":\n",
    "                output_activation_fn = F.relu\n",
    "                # fo = F.relu(fo)\n",
    "            elif self.output_activation == \"sp\":\n",
    "                output_activation_fn = F.softplus\n",
    "                # fo = F.softplus(fo)\n",
    "            elif self.output_activation == \"sm\":\n",
    "                # you shouldn't gate with sm\n",
    "                assert not self.bidirectional_prediction\n",
    "                assert not self.gate_prediction\n",
    "                assert not self.spectrum_attention\n",
    "                def output_activation_fn(x): return F.softmax(x, dim=1)\n",
    "                # fo = F.softmax(fo,dim=1)\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"invalid output_activation: {self.output_activation}\")\n",
    "            fo = output_activation_fn(fo)\n",
    "            # apply gt gating\n",
    "            if self.gt_gate_prediction:\n",
    "                # binarize gt spec\n",
    "                gt_fo = (data[\"spec\"] > 0.).float()\n",
    "                # map binary to [1-gt_gate_val,gt_gate_val]\n",
    "                assert self.gt_gate_val > 0.5\n",
    "                gt_fo = gt_fo * (2 * self.gt_gate_val - 1.) + \\\n",
    "                    (1. - self.gt_gate_val)\n",
    "                # multiply\n",
    "                fo = gt_fo * fo\n",
    "            # apply spectrum attention\n",
    "            if self.spectrum_attention:\n",
    "                fo = self.spectrum_attender(fo)\n",
    "                fo = output_activation_fn(fo)\n",
    "            # apply normalization\n",
    "            if self.output_normalization == \"l1\":\n",
    "                fo = F.normalize(fo, p=1, dim=1)\n",
    "            elif self.output_normalization == \"l2\":\n",
    "                fo = F.normalize(fo, p=2, dim=1)\n",
    "            elif self.output_normalization == \"none\":\n",
    "                pass\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"invalid output_normalization: {self.output_normalization}\")\n",
    "            output_d = {\"pred\":fo}\n",
    "            if return_input_feats:\n",
    "                output_d[\"input_feats\"] = input_feats\n",
    "            return output_d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
